import streamlit as st
import folium
from streamlit_folium import folium_static
import json
import pandas as pd
import os
import json
import plotly.express as px
from datetime import datetime
import io
import numpy as np
import altair as alt 
import requests
import folium

# --- Fun√ß√µes Auxiliares ---
def create_formatted_crosstab(df_data, index_col, col_col):
    counts = pd.crosstab(df_data[index_col], df_data[col_col])
    percs = pd.crosstab(df_data[index_col], df_data[col_col], normalize='columns').mul(100).round(2)
    formatted_df = pd.DataFrame(index=counts.index)
    for c in counts.columns:
        formatted_df[c] = counts[c]
        formatted_df[f'{c} (%)'] = percs[c]
    sorted_cols = []
    for c in counts.columns:
        sorted_cols.append(c)
        sorted_cols.append(f'{c} (%)')
    formatted_df = formatted_df[sorted_cols]
    total_row_counts = counts.sum(axis=0)
    total_row_percs = pd.Series([100.0] * len(counts.columns), index=counts.columns)
    total_row_data = {}
    for c in counts.columns:
        total_row_data[c] = total_row_counts[c]
        total_row_data[f'{c} (%)'] = total_row_percs[c]
    total_df_row = pd.DataFrame([total_row_data], index=['Total respondentes'])
    return pd.concat([formatted_df, total_df_row])


# --- Configura√ß√µes da P√°gina Streamlit ---
st.set_page_config(
    page_title="Dashboard de An√°lise do RF",
    layout="wide",
    initial_sidebar_state="expanded"
)


# --- Carregar os Dados (apenas uma vez por sess√£o) ---
# Caminhos para os dois arquivos CSV e o GeoJSON
FILE_PATH_MAIN_DATA = os.path.join("data", "questionario.csv") # SEU ARQUIVO PRINCIPAL
FILE_PATH_SENTIMENT_DATA = os.path.join("data", "questionario_analisado.csv") # SEU ARQUIVO DE SENTIMENTOS
FILE_PATH_GEOJSON = os.path.join("data", "geojs-uf.json") # SEU GEOJSON (pontos)

# Caminho do GeoJSON dos estados do Brasil
geojson_path = 'data/geojs-uf.json'  

# Carregar GeoJSON
with open(geojson_path, encoding='utf-8') as f:
    estados_geojson = json.load(f)


if 'main_data_loaded' not in st.session_state: # Flag para carregar uma √∫nica vez
    
    # --- Carregar DataFrame Principal ---
    if not os.path.exists(FILE_PATH_MAIN_DATA):
        st.error(f"ERRO CR√çTICO: O arquivo de dados principal '{FILE_PATH_MAIN_DATA}' N√ÉO FOI ENCONTRADO. "
                 "Verifique o nome do arquivo, a pasta 'data/'.")
        st.stop()
    try:
        df_main_loaded = pd.read_csv(FILE_PATH_MAIN_DATA, sep=';', encoding='utf-8')
        df_main_loaded.columns = df_main_loaded.columns.str.strip()
        
        # Pr√©-processamento de ID3 para Idade no DF principal
        if 'ID3' in df_main_loaded.columns:
            df_main_loaded['ID3_datetime'] = pd.to_datetime(df_main_loaded['ID3'], errors='coerce', dayfirst=True)
            today = datetime(2025, 7, 3) 
            df_main_loaded['Idade'] = (today.year - df_main_loaded['ID3_datetime'].dt.year) - \
                                 ((today.month < df_main_loaded['ID3_datetime'].dt.month) | \
                                  ((today.month == df_main_loaded['ID3_datetime'].dt.month) & \
                                   (today.day < df_main_loaded['ID3_datetime'].dt.day)))
            df_main_loaded.loc[df_main_loaded['Idade'] < 0, 'Idade'] = pd.NA
            df_main_loaded.loc[df_main_loaded['Idade'] > 120, 'Idade'] = pd.NA
        else:
            df_main_loaded['Idade'] = pd.NA
        
        st.session_state['df_original_main'] = df_main_loaded.copy()
        #st.success(f"Dados principais ('{FILE_PATH_MAIN_DATA}') carregados com sucesso! Total de {len(st.session_state.df_original_main)} linhas.")
       # st.info("Colunas do DataFrame Principal: " + ", ".join(st.session_state.df_original_main.columns.tolist()))

    except Exception as e:
        st.error(f"ERRO CR√çTICO: Falha ao carregar ou processar '{FILE_PATH_MAIN_DATA}': {e}. Verifique separador, encoding ou integridade.")
        st.stop()

    # --- Carregar DataFrame de Sentimentos ---
    if not os.path.exists(FILE_PATH_SENTIMENT_DATA):
        st.warning(f"AVISO: O arquivo de dados de sentimento '{FILE_PATH_SENTIMENT_DATA}' N√ÉO FOI ENCONTRADO. "
                   "As an√°lises de sentimento n√£o estar√£o dispon√≠veis. Execute 'processar_sentimentos.py'.")
        st.session_state['df_original_sentiment'] = pd.DataFrame() # Cria um DF vazio para evitar erros
    else:
        try:
            df_sentiment_loaded = pd.read_csv(FILE_PATH_SENTIMENT_DATA, sep=';', encoding='utf-8')
            df_sentiment_loaded.columns = df_sentiment_loaded.columns.str.strip()
            st.session_state['df_original_sentiment'] = df_sentiment_loaded.copy()
            #st.success(f"Dados de sentimento ('{FILE_PATH_SENTIMENT_DATA}') carregados com sucesso! Total de {len(st.session_state.df_original_sentiment)} linhas.")
        except Exception as e:
            st.error(f"ERRO CR√çTICO: Falha ao carregar ou processar '{FILE_PATH_SENTIMENT_DATA}': {e}.")
            st.session_state['df_original_sentiment'] = pd.DataFrame() # Cria um DF vazio
    
    # --- Carregar o arquivo GeoJSON ---
    if not os.path.exists(FILE_PATH_GEOJSON):
        st.error(f"ERRO CR√çTICO: O arquivo GeoJSON '{FILE_PATH_GEOJSON}' N√ÉO FOI ENCONTRADO. "
                 "Certifique-se de que ele est√° na pasta 'data/'.")
        st.stop()
    try:
        with open(FILE_PATH_GEOJSON, 'r', encoding='utf-8') as f:
            st.session_state['geojson_data'] = json.load(f)
        
        # DEBUG: Verifica o tipo de geometria no GeoJSON
        first_feature_type = st.session_state['geojson_data']['features'][0]['geometry']['type'] if st.session_state['geojson_data']['features'] else 'N/A'
        if first_feature_type not in ['Point', 'Polygon', 'MultiPolygon']: # Se n√£o for nem ponto nem pol√≠gono
             st.warning(f"AVISO: O GeoJSON carregado parece conter geometrias do tipo '{first_feature_type}'. O mapa pode n√£o ser exibido corretamente. Esperado 'Point', 'Polygon' ou 'MultiPolygon'.")
       # st.success(f"Mapa GeoJSON ('{FILE_PATH_GEOJSON}') carregado com sucesso!")
    except Exception as e:
        st.error(f"ERRO CR√çTICO: Falha ao carregar o arquivo GeoJSON: {e}")
        st.stop()
    
    st.session_state['main_data_loaded'] = True # Define a flag para que o carregamento n√£o se repita

#else:
  #  st.info(f"Dados e GeoJSON j√° carregados (usando cache da sess√£o).")


# DF principal para filtros e an√°lises (copiado do original para resetar filtros)
df_main = st.session_state.df_original_main.copy() 
# DF de sentimentos (separado para an√°lises espec√≠ficas)
df_sentiment = st.session_state.df_original_sentiment.copy() 


# --- DEFINI√á√ÉO DE GRUPOS DE QUEST√ïES E SEUS R√ìTULOS COMPLETOS ---
# Atualiza question_labels para incluir colunas de sentimentos com base no df_sentiment
# e outras colunas que podem n√£o estar no df_main
question_labels = {
    # Identifica√ß√£o
    'ID3': 'ID3 - Qual sua data de nascimento?', 'Idade': 'Idade (Calculada)', 'ID7': 'ID7 - Ra√ßa/Cor',
    'ADAI_ID8': 'ADAI_ID8 - Qual seu sexo?', 'ID8': 'ID8 - G√™nero', 'ID9': 'ID9 - Orienta√ß√£o sexual:',
    'ID10': 'ID10 - √â pessoa com defici√™ncia?', 'ID10.1': 'ID10.1 - Qual o tipo de defici√™ncia?',
    'ID11': 'ID11 - Qual sua escolaridade?', 'ID12': 'ID12 - √â adepto de alguma dessas pr√°ticas religiosas?',
    'ADAI_ID12': 'ADAI_ID12 - Qual(is) a(s) sua(s) profiss√£o(√µes)?',
    'PCT0': 'PCT0 - Voc√™ e/ou seu n√∫cleo familiar pertencem a algum povo ou comunidade tradicional?',
    'NF1': 'NF1 - Quantas pessoas comp√µem o n√∫cleo familiar?',
    'ADAI_CT4': 'ADAI_CT4 - O territ√≥rio ao qual pertence o entrevistado est√° em qual dessas localidades?',

    # Colunas de Sentimento (NOME PRECISA SER EXATO NO questionario_analisado.csv)
    # Use os nomes curtos 'PCT5.1', 'PC1.1.8.1', 'ADAI_PC2' pois o processador renomeia para estes.
    'PCT5.1_Sentimento_Geral': 'PCT5.1 - Sentimento Geral (Modos de Vida)',
    'PCT5.1_Sentimento_Satisfacao': 'PCT5.1 - Satisfa√ß√£o (Modos de Vida)',
    'PCT5.1_Sentimento_Emocao': 'PCT5.1 - Emo√ß√£o (Modos de Vida)',
    'PCT5.1_Sentimento_Justificativa': 'PCT5.1 - Trecho Chave (Modos de Vida)', 
    
    'PC1.1.8.1_Sentimento_Geral': 'PC1.1.8.1 - Sentimento Geral (Sugest√µes Repara√ß√£o)',
    'PC1.1.8.1_Sentimento_Satisfacao': 'PC1.1.8.1 - Satisfa√ß√£o (Sugest√µes Repara√ß√£o)',
    'PC1.1.8.1_Sentimento_Emocao': 'PC1.1.8.1 - Emo√ß√£o (Sugest√µes Repara√ß√£o)',
    'PC1.1.8.1_Sentimento_Justificativa': 'PC1.1.8.1 - Trecho Chave (Sugest√µes Repara√ß√£o)',

    'ADAI_PC2_Sentimento_Geral': 'ADAI_PC2 - Sentimento Geral (Avalia√ß√£o Participa√ß√£o)',
    'ADAI_PC2_Sentimento_Satisfacao': 'ADAI_PC2 - Satisfa√ß√£o (Avalia√ß√£o Participa√ß√£o)',
    'ADAI_PC2_Sentimento_Emocao': 'ADAI_PC2 - Emo√ß√£o (Avalia√ß√£o Participa√ß√£o)',
    'ADAI_PC2_Sentimento_Justificativa': 'ADAI_PC2 - Trecho Chave (Avalia√ß√£o Participa√ß√£o)',
    
    # Condi√ß√µes de Acesso √†s Fontes H√≠dricas
    'DM11': 'DM11 - Tipo de esgotamento sanit√°rio', 'DM12': 'DM12 - Abastecimento de energia el√©trica', 'DM13': 'DM13 - Destino do lixo', 
    'ADAI_AQAMN2': 'ADAI_AQAMN2 - Uso dom√©stico de rios/a√ßudes', 'AQA3': 'AQA3 - D√∫vida sobre qualidade da √°gua', 'AQA6.1': 'AQA6.1 - Avalia√ß√£o da altera√ß√£o na √°gua', 
    'EC2': 'EC2 - Domic√≠lio exposto a rejeitos?', 'ADAI_PCE1.2.1.1': 'ADAI_PCE1.2.1.1 - Dificuldade de acesso a outros equipamentos',

    # Condi√ß√µes de Sa√∫de/Socioassist√™ncia
    'CAI1': 'CAI1 - Acesso √† internet?', 'PCT2.1': 'PCT2.1 - Mudan√ßas na rela√ß√£o com o territ√≥rio', 'EC4.2.2': 'EC4.2.2 - Doen√ßas ap√≥s enchentes', 
    'ADAI_CSS1': 'ADAI_CSS1 - Fatores de vulnerabilidade surgiram/aumentaram', 'CCS1': 'CCS1 - Fatores que influenciaram sa√∫de da comunidade', 
    'CCS2': 'CCS2 - Fatores que influenciaram sua sa√∫de', 'CCS3': 'CCS3 - Agravos de sa√∫de surgiram?', 
    'CCS4.2.1': 'CCS4.2.1 - Onde buscou cuidado de sa√∫de?', 'CCS4.2.1.1': 'CCS4.2.1.1 - Aumento busca UBS?', 
    'CCS5': 'CCS5 - Mant√©m pr√°ticas tradicionais de sa√∫de?', 'CCS7': 'CCS7 - Aumento gastos com sa√∫de?',

    # Seguran√ßa/Inseguran√ßa Alimentar
    'SA1': 'SA1 - Comprometimento qualidade de alimentos?', 'SA1.1': 'SA1.1 - Raz√£o diminui√ß√£o qualidade alimentos', 'SA3': 'SA3 - Diminui√ß√£o quantidade de alimentos?', 
    'SA4': 'SA4 - Formas de acesso a alimentos ANTES', 'SA5': 'SA5 - Formas de acesso a alimentos DEPOIS', 
    'SA6.1': 'SA6.1 - Deixou de consumir alimento da regi√£o?', 'ADAI_SA7': 'ADAI_SA7 - Preocupa√ß√£o c/ falta de comida?',

    # Quest√µes de Acesso aos Programas
    'ID13': 'ID13 - Acessava programas sociais ANTES?',
    'ID14': 'ID14 - Acessou programas sociais DEPOIS?', 
    'ID15': 'ID15 - Aumento atividades/tarefas mulheres?', 'ID15.1': 'ID15.1 - Quais atividades mulheres aumentaram?', 'ID15.2': 'ID15.2 - Quais atividades mulheres diminu√≠ram?',
    'AD2': 'AD2 - Aumento de despesas?', 'AD2.2': 'AD2.2 - Quais despesas aumentaram?',
    'CAD1': 'CAD1 - Solicitou cadastro Renova?', 'CAD1.1': 'CAD1.1 - Categorias/danos informados no cadastro?', 'CAD1.1.1': 'CAD1.1.1 - Quais categorias/danos no cadastro?', 'CAD2': 'CAD2 - Recebeu resposta sobre cadastro?', 'CAD2.1': 'CAD2.1 - Cadastro aprovado?', 'CAD3': 'CAD3 - O que constou no cadastro correspondeu ao declarado?', 'CAD3.1': 'CAD3.1 - Solicitou revis√£o de cadastro?', 'CAD3.1.1': 'CAD3.1.1 - Cadastro revisado?', 'PRM1': 'PRM1 - Recebeu indeniza√ß√£o individual?', 'PRM1.1': 'PRM1.1 - N√£o recebeu por recusar quita√ß√£o geral?', 'PRM1.2': 'PRM1.2 - Informado sobre quita√ß√£o geral (NOVEL)?', 'PRM1.2.1': 'PRM1.2.1 - Danos informados NOVEL?', 'PRM1.3': 'PRM1.3 - Informado sobre quita√ß√£o geral (PIM)?', 'PRM1.3.1': 'PRM1.3.1 - Danos informados PIM?', 'PRM1.5': 'PRM1.5 - Informado sobre interrup√ß√£o AFE?', 'PRM1.7': 'PRM1.7 - Dimens√µes n√£o indenizadas NOVEL?', 'PRM1.8': 'PRM1.8 - Dimens√µes n√£o indenizadas PIM?', 'PRM1.4': 'PRM1.4 - Recebeu parcelas anuais PIM?', 'PRM1.4.2': 'PRM1.4.2 - Por que parou de receber PIM?', 'PRM1.4.3': 'PRM1.4.3 - Valor PIM equivalente ao antes?',

    # Mudan√ßas no Acesso a Benef√≠cios Sociais e Pol√≠ticas P√∫blicas P√≥s-Rompimento
    'ID13.1': 'ID13.1 - Outros programas acessados ANTES?', 'ID14.1': 'ID14.1 - Outros programas acessados DEPOIS?', 'ID16': 'ID16 - Possui CAD√öNICO?',

    # Impacto no Trabalho e na Renda
    'AER1': 'AER1 - Exercia atividade remunerada ANTES?', 
    'AER2': 'AER2 - Possu√≠a empresa ANTES?', 'AER3': 'AER3 - Recebia outro recurso ANTES?', 'AER3.1': 'AER3.1 - De onde provinha outro recurso ANTES?',
    'ARF1.3': 'ARF1.3 - Atividades de subsist√™ncia ALTERADAS?', 'ARF1.3.3.1': 'ARF1.3.3.1 - Documento que comprove diminui√ß√£o renda?',
    'ARF3.1': 'ARF3.1 - Documento que comprove perda de renda?', 'PRM3': 'PRM3 - Solicitou AFE?', 'PRM3.1': 'PRM3.1 - Recebeu AFE?', 'PRM3.1.1': 'PRM3.1.1 - Ainda recebe AFE?', 'PRM3.1.1.1': 'PRM3.1.1.1 - Justificativa cancelamento AFE?', 'PRM3.1.1.1.1': 'PRM3.1.1.1.1 - Motivo interrup√ß√£o AFE?',
    'ARF1.1': 'ARF1.1 - Quais atividades de subsist√™ncia realizadas?', 

    # Endividamento e Perda de Patrim√¥nio
    'DP1': 'DP1 - Patrim√¥nio desvalorizou/perdeu valor?', 'DP2': 'DP2 - Vendeu patrim√¥nio para se manter/quitar d√≠vidas?',
    'DF1': 'DF1 - Contraiu/aumentou d√≠vida?', 'DF1.1': 'DF1.1 - Tipo de d√≠vida?', 'DF1.2': 'DF1.2 - Valor d√≠vida atual?', 'DF1.4': 'DF1.4 - Documento que comprove d√≠vida?',
}

# Dicion√°rio para agrupar os c√≥digos das quest√µes
# Usamos os nomes curtos para as colunas de sentimento aqui
question_groups = {
    "Identifica√ß√£o": [
        'ID3', 'Idade', 'ID7', 'ADAI_ID8', 'ID8', 'ID9', 'ID10', 'ID10.1', 'ID11', 'ID12', 'ADAI_ID12', 'PCT0', 'NF1', 'ADAI_CT4'
    ], 
    "Sentimentos e Percep√ß√µes": [ # Colunas de sentimentos - agora usando nomes curtos
        'PCT5.1_Sentimento_Geral', 'PCT5.1_Sentimento_Satisfacao', 'PCT5.1_Sentimento_Emocao', 'PCT5.1_Sentimento_Justificativa',
        'PC1.1.8.1_Sentimento_Geral', 'PC1.1.8.1_Sentimento_Satisfacao', 'PC1.1.8.1_Sentimento_Emocao', 'PC1.1.8.1_Sentimento_Justificativa',
        'ADAI_PC2_Sentimento_Geral', 'ADAI_PC2_Sentimento_Satisfacao', 'ADAI_PC2_Sentimento_Emocao', 'ADAI_PC2_Sentimento_Justificativa'
    ],
    "Condi√ß√µes de Acesso √†s Fontes H√≠dricas": [
        'DM11', 'DM12', 'DM13', 'ADAI_AQAMN2', 'AQA3', 'AQA6.1', 'EC2', 'ADAI_PCE1.2.1.1'
    ],
    "Condi√ß√µes de Sa√∫de/Socioassist√™ncia": [
        'CAI1', 'PCT2.1', 'EC4.2.2', 'ADAI_CSS1', 'CCS1', 'CCS2', 'CCS3', 'CCS4.2.1', 'CCS4.2.1.1', 'CCS5', 'CCS7'
    ],
    "Seguran√ßa/Inseguran√ßa Alimentar": [
        'SA1', 'SA1.1', 'SA3', 'SA4', 'SA5', 'SA6.1', 'ADAI_SA7'
    ],
    "Quest√µes de Acesso aos Programas": [
        'ID13', 'ID14', 'ID15', 'ID15.1', 'ID15.2', 'AD2', 'AD2.2', 'CAD1', 'CAD1.1', 'CAD1.1.1', 'CAD2', 'CAD2.1',
        'CAD3', 'CAD3.1', 'CAD3.1.1', 'PRM1', 'PRM1.1', 'PRM1.2', 'PRM1.2.1', 'PRM1.3', 'PRM1.3.1', 'PRM1.5',
        'PRM1.7', 'PRM1.8', 'PRM1.4', 'PRM1.4.2', 'PRM1.4.3'
    ],
    "Mudan√ßas no Acesso a Benef√≠cios Sociais e Pol√≠ticas P√∫blicas P√≥s-Rompimento": [
        'ID13', 'ID13.1', 'ID14', 'ID14.1', 'ID16'
    ],
    "Impacto no Trabalho e na Renda": [
        'AER1', 'AER2', 'AER3', 'AER3.1', 'ARF1.3', 'ARF1.3.3.1', 'ARF3.1', 'PRM3', 'PRM3.1', 'PRM3.1.1',
        'PRM3.1.1.1', 'PRM3.1.1.1.1'
    ],
    "Endividamento e Perda de Patrim√¥nio": [
        'DP1', 'DP2', 'DF1', 'DF1.1', 'DF1.2', 'DF1.4'
    ]
}

# Filtra apenas as colunas que realmente existem no DataFrame principal (df_original_main)
available_cols_in_df_main = st.session_state.df_original_main.columns.tolist() 
# E as colunas de sentimento que existem no df_original_sentiment
available_cols_in_df_sentiment = st.session_state.df_original_sentiment.columns.tolist()

filtered_question_groups = {}
for group_name, cols in question_groups.items():
    if group_name == "Sentimentos e Percep√ß√µes":
        # Para sentimentos, verifique se as colunas est√£o no df_sentiment
        filtered_cols = [col for col in cols if col in available_cols_in_df_sentiment]
    else:
        # Para outros grupos, verifique se as colunas est√£o no df_main
        filtered_cols = [col for col in cols if col in available_cols_in_df_main]

    if filtered_cols:
        filtered_question_groups[group_name] = filtered_cols

# all_selectable_categorical_cols deve incluir colunas de ambos os DFs se forem usadas para cruzamento
all_selectable_categorical_cols = sorted(list(set(
    [col for cols_list in filtered_question_groups.values() if cols_list for col in cols_list]
)))


# --- SIDEBAR (MENU LATERAL) ---
# Adicionando a logo
logo_path = "imagens/logo_adai.png" 
if os.path.exists(logo_path):
    st.sidebar.image(logo_path, caption='https://adaibrasil.org.br/', use_container_width=True)
else:
    st.sidebar.warning(f"Logo n√£o encontrada em: {logo_path}")

st.sidebar.title("Associa√ß√£o de Desenvolvimento Agr√≠cola Interestadual | ADAI")
st.sidebar.markdown("---")

st.sidebar.header("Filtros Globais")

# Filters now apply to df_main
# Op√ß√µes de localidade do DF principal
locality_options = ['Todas as Localidades'] + sorted(st.session_state.df_original_main['ADAI_CT4'].dropna().unique().tolist())
selected_locality = st.sidebar.selectbox(
    "Filtrar por Localidade:",
    locality_options,
    key="global_locality_filter"
)

gender_options = sorted(st.session_state.df_original_main['ADAI_ID8'].dropna().unique().tolist())
selected_gender = st.sidebar.multiselect(
    "Filtrar por G√™nero:",
    gender_options,
    default=gender_options, # Seleciona todos por padr√£o
    key="global_gender_filter"
)

race_options = sorted(st.session_state.df_original_main['ID7'].dropna().unique().tolist())
selected_race = st.sidebar.multiselect(
    "Filtrar por Ra√ßa/Cor:",
    race_options,
    default=race_options, # Seleciona todos por padr√£o
    key="global_race_filter"
)

if 'Idade' in st.session_state.df_original_main.columns and not st.session_state.df_original_main['Idade'].dropna().empty:
    min_age = int(st.session_state.df_original_main['Idade'].min())
    max_age = int(st.session_state.df_original_main['Idade'].max())
    age_range = st.sidebar.slider(
        "Filtrar por Faixa Et√°ria:",
        min_value=min_age,
        max_value=max_age,
        value=(min_age, max_age),
        key="global_age_filter"
    )
else:
    age_range = (0, 120)
    st.sidebar.info("Coluna 'Idade' n√£o dispon√≠vel ou sem dados para filtro.")

# --- Filtro Global por Sentimento (NOVO) ---
# Este filtro se baseia nas colunas de sentimento do DF de sentimentos
all_general_sentiment_cols_in_df_sentiment = [col for col in df_sentiment.columns if col.endswith('_Sentimento_Geral')]
available_sentiment_options = []
if all_general_sentiment_cols_in_df_sentiment:
    for col_s in all_general_sentiment_cols_in_df_sentiment:
        available_sentiment_options.extend(df_sentiment[col_s].dropna().unique().tolist())
    available_sentiment_options = sorted(list(set(available_sentiment_options)))

    selected_sentiment_filter = st.sidebar.multiselect(
        "Filtrar por Sentimento Geral (An√°lise):", 
        available_sentiment_options,
        default=available_sentiment_options,
        key="global_sentiment_filter_new"
    )
else:
    selected_sentiment_filter = []
    st.sidebar.info("Colunas de Sentimento Geral (de an√°lise) n√£o dispon√≠veis para filtro. Execute o script de processamento.")


# --- Aplica todos os filtros ao DataFrame PRINCIPAL (df_main) ---
df_filtered_main = st.session_state.df_original_main.copy()

if selected_locality != 'Todas as Localidades':
    df_filtered_main = df_filtered_main[df_filtered_main['ADAI_CT4'] == selected_locality]

if selected_gender:
    df_filtered_main = df_filtered_main[df_filtered_main['ADAI_ID8'].isin(selected_gender)]

if selected_race:
    df_filtered_main = df_filtered_main[df_filtered_main['ID7'].isin(selected_race)]

df_filtered_main = df_filtered_main[
    (df_filtered_main['Idade'].fillna(-1) >= age_range[0]) & 
    (df_filtered_main['Idade'].fillna(-1) <= age_range[1])
]

# AQUI: Se o filtro de sentimento for aplicado, precisamos combin√°-lo com o DF principal.
# Isso requer que ambos os DFs (principal e sentimento) tenham uma coluna de ID para merge.
# Assumindo que a coluna 'ID' √© a chave para uni√£o
if selected_sentiment_filter and all_general_sentiment_cols_in_df_sentiment and 'ID' in df_main.columns and 'ID' in df_sentiment.columns:
    # Cria uma m√°scara no DF de sentimentos primeiro
    mask_sentiment_df = pd.Series(False, index=df_sentiment.index)
    for col_s in all_general_sentiment_cols_in_df_sentiment:
        if col_s in df_sentiment.columns:
            mask_sentiment_df = mask_sentiment_df | df_sentiment[col_s].isin(selected_sentiment_filter)
    
    # Pega os IDs dos respondentes que atendem ao filtro de sentimento
    ids_from_sentiment_filter = df_sentiment.loc[mask_sentiment_df, 'ID'].unique()
    
    # Filtra o DF principal usando esses IDs
    df_filtered_main = df_filtered_main[df_filtered_main['ID'].isin(ids_from_sentiment_filter)]
elif selected_sentiment_filter and not all_general_sentiment_cols_in_df_sentiment:
    st.sidebar.warning("Filtro de Sentimento Geral aplicado, mas as colunas de sentimento n√£o foram encontradas no DataFrame de an√°lise. Sem efeito.")


# Atualiza o DataFrame principal na session_state para todas as an√°lises
st.session_state['df'] = df_filtered_main.copy()
df = st.session_state.df # Vari√°vel 'df' agora sempre aponta para o df principal filtrado

# --- DF de Sentimentos Filtrado (para uso nas an√°lises de sentimento) ---
# Filtra o df_sentiment APENAS pelos IDs presentes no df_filtered_main.
# Isso garante que a an√°lise de sentimento respeite os filtros demogr√°ficos.
if 'ID' in df_sentiment.columns and 'ID' in df.columns:
    df_sentiment_filtered_by_main = df_sentiment[df_sentiment['ID'].isin(df['ID'])]
else:
    df_sentiment_filtered_by_main = df_sentiment.copy() # Se n√£o houver ID para merge, usa o DF de sentimento completo


# Feedback sobre o n√∫mero de entrevistados ap√≥s a filtragem
if not df.empty:
    st.sidebar.success(f"Dados filtrados. Total de **{len(df)}** entrevistados.")
else:
    st.sidebar.warning("Nenhum entrevistado encontrado com os filtros aplicados.")


st.sidebar.markdown("---")

modo_admin = st.sidebar.checkbox("üîß Modo Admin (mostrar detalhes t√©cnicos)", value=False)

st.sidebar.header("Escolha o Tipo de An√°lise")
analysis_type = st.sidebar.radio(
    "Selecione o tipo de an√°lise:",
    (
     "üè† Home",
     "An√°lise de Categoria √önica",
     "An√°lise Cruzada de Quest√µes",
     "Visualiza√ß√£o por Mapa",
     "An√°lise de Sentimento por Tema",
     "An√°lise de Lacunas (Antes vs. Depois)",
     "An√°lise de Vulnerabilidade",
     "Sobre o Dashboard",
     "Sobre a IA"
     ),
    index=0,  # Sempre come√ßa na Home
    key="main_analysis_type"
)
st.sidebar.info("Para informa√ß√µes institucionais, selecione as op√ß√µes no menu acima.")


if analysis_type == "üè† Home":
    # Conte√∫do da Home
    st.title("üìä Dashboard de An√°lise do RF")
    st.markdown("---")
    st.markdown("""
    Bem-vindo ao painel de an√°lise dos dados do RF!  
    <br>
    Este dashboard permite explorar e analisar os dados do question√°rio de forma din√¢mica.  
    **Use o menu lateral** para selecionar o tipo de an√°lise desejada:  
    - Visualize mapas, cruzamentos, gr√°ficos, tabelas e relat√≥rios.
    - Aplique filtros por territ√≥rio, ra√ßa/cor, g√™nero, faixa et√°ria, etc.
    - Use a intelig√™ncia artificial para obter insights autom√°ticos.
    
    <br>
    Para d√∫vidas ou sugest√µes, fale com a equipe t√©cnica do projeto.
    """, unsafe_allow_html=True)
    # Voc√™ pode colocar aqui instru√ß√µes, imagens, link para documenta√ß√£o, etc.

# ... os demais blocos

if modo_admin:
    st.success(f"Dados principais ('{FILE_PATH_MAIN_DATA}') carregados com sucesso! Total de {len(st.session_state.df_original_main)} linhas.")
    st.success(f"Dados de sentimento ('{FILE_PATH_SENTIMENT_DATA}') carregados com sucesso! Total de {len(st.session_state.df_original_sentiment)} linhas.")
    st.success("Dados carregados e painel pronto para an√°lise.")
    st.success(f"Mapa GeoJSON ('{FILE_PATH_GEOJSON}') carregado com sucesso!")

st.sidebar.markdown("---")

st.sidebar.markdown("<h3 style='text-align: center;'>A√ß√µes e Informa√ß√µes</h3>", unsafe_allow_html=True)

st.sidebar.write("---")
if st.sidebar.button("Resetar Filtros", use_container_width=True):
    st.session_state['global_locality_filter'] = 'Todas as Localidades'
    if 'global_gender_filter' in st.session_state: st.session_state['global_gender_filter'] = gender_options
    if 'global_race_filter' in st.session_state: st.session_state['global_race_filter'] = race_options
    
    if 'Idade' in st.session_state.df_original_main.columns and not st.session_state.df_original_main['Idade'].dropna().empty:
        st.session_state['global_age_filter'] = (int(st.session_state.df_original_main['Idade'].min()), int(st.session_state.df_original_main['Idade'].max()))
    else: st.session_state['global_age_filter'] = (0, 120)

    if 'global_sentiment_filter_new' in st.session_state and available_sentiment_options: 
        st.session_state['global_sentiment_filter_new'] = available_sentiment_options
    elif 'global_sentiment_filter_new' in st.session_state:
        st.session_state['global_sentiment_filter_new'] = []
    
    st.session_state['df'] = st.session_state.df_original_main.copy() # Reseta para o DF principal original
    st.rerun() 

if st.sidebar.button("Limpar Dashboard", use_container_width=True):
    st.session_state['df'] = st.session_state.df_original_main.copy() # Limpa para o DF principal original
    if 'main_analysis_type' in st.session_state: del st.session_state['main_analysis_type'] 
    
    st.session_state['global_locality_filter'] = 'Todas as Localidades'
    if 'global_gender_filter' in st.session_state: st.session_state['global_gender_filter'] = gender_options
    if 'global_race_filter' in st.session_state: st.session_state['global_race_filter'] = race_options
    if 'Idade' in st.session_state.df_original_main.columns and not st.session_state.df_original_main['Idade'].dropna().empty:
        st.session_state['global_age_filter'] = (int(st.session_state.df_original_main['Idade'].min()), int(st.session_state.df_original_main['Idade'].max()))
    else: st.session_state['global_age_filter'] = (0, 120)
    if 'global_sentiment_filter_new' in st.session_state and available_sentiment_options:
        st.session_state['global_sentiment_filter_new'] = available_sentiment_options
    elif 'global_sentiment_filter_new' in st.session_state:
        st.session_state['global_sentiment_filter_new'] = []
            
    st.rerun()

st.sidebar.write("---")


st.markdown("---")

# --- Renderiza√ß√£o do Conte√∫do Principal com base no Tipo de An√°lise ---

# BLOCO 0: Sobre o Dashboard (Mantido, mas fora da ordem num√©rica para n√£o confundir com os blocos que voc√™ pediu)
if analysis_type == "Sobre o Dashboard":
    st.header("Sobre o Dashboard, Metadados e M√©todos Estat√≠sticos")
    st.markdown("""
    ## O que √© este painel?

    Este dashboard foi desenvolvido para **an√°lise interativa, estat√≠stica e explorat√≥ria** dos dados coletados em question√°rios aplicados no contexto da pesquisa [NOME/TEMA DA PESQUISA]. O painel foi idealizado para facilitar a compreens√£o, interpreta√ß√£o e comunica√ß√£o dos resultados tanto para especialistas quanto para gestores, pesquisadores e p√∫blico geral.

    ### Principais funcionalidades do painel

    - Visualiza√ß√£o din√¢mica de dados categ√≥ricos, quantitativos e abertos.
    - Cruzamentos autom√°ticos entre vari√°veis para identificar padr√µes, tend√™ncias e poss√≠veis associa√ß√µes.
    - Visualiza√ß√£o espacial (mapa) para an√°lise territorial dos dados.
    - An√°lise de lacunas (antes vs. depois), vulnerabilidades e distribui√ß√£o por grupo demogr√°fico.
    - Download f√°cil das tabelas em formatos CSV e Excel.
    - Apoio automatizado de **Intelig√™ncia Artificial** para interpreta√ß√£o r√°pida de dados e respostas abertas.

    ## Metadados dos dados

    - **Fonte**: [descrever de onde v√™m os dados, por exemplo: levantamento prim√°rio, institui√ß√£o, projeto, etc.]
    - **Popula√ß√£o-alvo**: [descrever o perfil da popula√ß√£o entrevistada]
    - **Per√≠odo de coleta**: [data inicial - data final]
    - **N√∫mero de respondentes v√°lidos**: [colocar n√∫mero]
    - **Principais campos**: identifica√ß√£o, dados sociodemogr√°ficos, condi√ß√µes de sa√∫de, trabalho, acesso a programas, percep√ß√µes, sentimentos e impactos do rompimento.

    ## M√©todos estat√≠sticos e matem√°ticos aplicados

    - **Estat√≠stica descritiva**: c√°lculo de frequ√™ncias absolutas e relativas, m√©dias, medianas, m√≠nimos, m√°ximos, desvios-padr√£o (quando aplic√°vel).
    - **Tabelas de conting√™ncia**: cruzamento autom√°tico de vari√°veis categ√≥ricas, an√°lise de distribui√ß√µes condicionais.
    - **Compara√ß√µes de grupos**: filtros para subgrupos de acordo com territ√≥rio, idade, ra√ßa/cor, g√™nero, etc.
    - **Visualiza√ß√£o**: gr√°ficos de barras, pizza, histogramas, mapas de calor, mapas espaciais.
    - **An√°lise automatizada de texto**: uso de modelos de linguagem (IA) para classifica√ß√£o de sentimento, emo√ß√£o e sumariza√ß√£o de respostas abertas.

    ## Limita√ß√µes e recomenda√ß√µes

    - Os resultados apresentados s√£o descritivos/explorat√≥rios. Recomenda-se a an√°lise detalhada por especialistas para interpreta√ß√µes finais.
    - N√£o h√° pondera√ß√£o amostral autom√°tica (salvo ajuste manual).
    - Em respostas abertas, a classifica√ß√£o √© feita por algoritmos de IA ‚Äî sempre validar com revis√£o humana em casos sens√≠veis.
    - O painel depende da qualidade dos dados fornecidos (aus√™ncias, respostas m√∫ltiplas, inconsist√™ncias podem afetar as an√°lises).

    ---
    **Dica:** Para entender como funciona a intelig√™ncia artificial do painel e seus limites, clique em "Sobre a IA" no menu lateral.
    """)

elif analysis_type == "Sobre a IA":
    st.header("Sobre a Intelig√™ncia Artificial do Painel")
    st.markdown("""
    Este painel utiliza **Intelig√™ncia Artificial (IA)** para auxiliar na an√°lise e interpreta√ß√£o dos dados de duas formas principais:

    ### 1. An√°lise Automatizada de Respostas Abertas
    - As respostas de texto livre dos question√°rios passam por um processamento automatizado com IA de linguagem natural, que identifica **sentimentos gerais, emo√ß√µes e justificativas chave**.
    - O modelo classifica sentimentos em categorias como ‚ÄúMuito Negativo‚Äù, ‚ÄúNegativo‚Äù, ‚ÄúNeutro‚Äù, ‚ÄúPositivo‚Äù e ‚ÄúMuito Positivo‚Äù, al√©m de mapear emo√ß√µes mais frequentes.
    - Trechos significativos das respostas podem ser destacados como exemplos para ilustrar o que os respondentes est√£o sentindo ou sugerindo.

    ### 2. Apoio √† Interpreta√ß√£o dos Dados
    - A IA resume tend√™ncias estat√≠sticas (mais frequentes), destaca mudan√ßas relevantes e pode sugerir insights iniciais automaticamente a partir dos filtros aplicados.
    - As interpreta√ß√µes autom√°ticas visam apoiar o usu√°rio n√£o-especialista, mas **n√£o substituem a leitura cr√≠tica humana** dos dados.

    ### Como funciona a IA aqui?
    - O painel utiliza modelos avan√ßados de linguagem (semelhantes ao ChatGPT), treinados para an√°lise de sentimento e sumariza√ß√£o de dados.
    - Para cada filtro ou an√°lise aplicada, a IA pode gerar resumos autom√°ticos sobre o perfil da amostra, sentimentos predominantes e exemplos de justificativas, sempre com base apenas nos dados filtrados.
    - Nenhum dado pessoal identific√°vel √© exibido ou utilizado para treinamento posterior.

    ### Limita√ß√µes e Boas Pr√°ticas
    - A IA √© uma **ferramenta auxiliar**: sempre revise as interpreta√ß√µes, especialmente em temas sens√≠veis ou pol√™micos.
    - Em caso de d√∫vidas ou dados amb√≠guos, priorize a avalia√ß√£o por especialistas humanos.
    - A qualidade da an√°lise automatizada depende da clareza e completude das respostas dos entrevistados.

    ---
    Para sugest√µes ou d√∫vidas sobre a IA do painel, consulte a equipe t√©cnica respons√°vel pelo projeto.
    """)


# BLOCO 1: An√°lise de Categoria √önica
elif analysis_type == "An√°lise de Categoria √önica":
    st.header("An√°lise de Categoria √önica")
    st.write("Selecione um grupo e uma quest√£o para ver sua distribui√ß√£o de respostas.")

    if filtered_question_groups:
        selected_group = st.selectbox(
            "Selecione um Grupo de Quest√µes:",
            list(filtered_question_groups.keys()),
            key="group_selector"
        )

        if selected_group:
            # Decide qual DF usar para este grupo
            if selected_group == "Sentimentos e Percep√ß√µes":
                current_df_for_analysis = df_sentiment_filtered_by_main
            else:
                current_df_for_analysis = df  # df √© o df_main filtrado
            
            cols_in_selected_group = [col for col in filtered_question_groups[selected_group] if col in current_df_for_analysis.columns]
            options_for_selectbox = [("Selecione uma quest√£o", None)] + [(question_labels.get(col, col), col) for col in cols_in_selected_group]
            selected_option = st.selectbox(
                "Selecione uma Quest√£o para Analisar:",
                options_for_selectbox,
                format_func=lambda x: x[0],
                key="single_question_selector"
            )
            selected_column = selected_option[1]

            if selected_column:
                is_numeric_column = pd.api.types.is_numeric_dtype(current_df_for_analysis[selected_column]) and selected_column != 'NF1'

                if is_numeric_column:
                    st.subheader(f"Distribui√ß√£o de '{question_labels.get(selected_column, selected_column)}'")
                    fig_hist = px.histogram(
                        current_df_for_analysis.dropna(subset=[selected_column]),
                        x=selected_column,
                        title=f'Histograma de {question_labels.get(selected_column, selected_column)}',
                        nbins=20
                    )
                    st.plotly_chart(fig_hist, use_container_width=True)
                    st.markdown("#### Estat√≠sticas Descritivas")
                    st.dataframe(current_df_for_analysis[selected_column].describe().to_frame(), use_container_width=True)

                else:
                    contagem_geral = current_df_for_analysis[selected_column].dropna().value_counts()
                    total_respostas = len(current_df_for_analysis[selected_column].dropna())

                    if total_respostas == 0:
                        st.warning(f"Nenhuma resposta encontrada para a quest√£o '{question_labels.get(selected_column, selected_column)}'.")
                    else:
                        resultados_generais = pd.DataFrame({
                            'Resposta': contagem_geral.index,
                            'N√∫mero de Respostas': contagem_geral.values,
                            'Porcentagem (%)': (contagem_geral.values / total_respostas) * 100 
                        })
                        resultados_generais['Porcentagem (%)'] = resultados_generais['Porcentagem (%)'].round(2)
                        resultados_generais = resultados_generais.sort_values(by='N√∫mero de Respostas', ascending=False)

                        st.subheader(f"Distribui√ß√£o de Respostas para '{question_labels.get(selected_column, selected_column)}'")

                        col_display, col_chart = st.columns(2)
                        with col_display:
                            display_mode_general = st.radio(
                                "Escolha o que exibir:",
                                ("N√∫mero de Respostas", "Porcentagem (%)"),
                                index=0,
                                key=f"display_mode_{selected_column}"
                            )
                        with col_chart:
                            chart_type_general = st.radio(
                                "Escolha o tipo de gr√°fico:",
                                ("Barra Vertical", "Barra Horizontal", "Pizza"),
                                index=0,
                                key=f"chart_type_{selected_column}"
                            )
                        
                        st.dataframe(resultados_generais, use_container_width=True)

                        csv_data = resultados_generais.to_csv(index=False).encode('utf-8')
                        st.download_button(label="Baixar Tabela como CSV", data=csv_data, file_name=f"{selected_column}_distribuicao.csv", mime="text/csv", key=f"download_csv_{selected_column}")
                        
                        excel_buffer = io.BytesIO()
                        resultados_generais.to_excel(excel_buffer, index=False, engine='xlsxwriter')
                        excel_buffer.seek(0)
                        st.download_button(label="Baixar Tabela como Excel", data=excel_buffer.getvalue(), file_name=f"{selected_column}_distribuicao.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"download_excel_{selected_column}")
                        st.markdown("---")
                        st.info("Para baixar o gr√°fico, clique com o bot√£o direito sobre ele e selecione 'Salvar imagem como...' ou 'Baixar imagem'.")

                        if chart_type_general == "Barra Vertical":
                            fig_general = px.bar(resultados_generais, x='Resposta', y=display_mode_general, title=f'Distribui√ß√£o de Respostas para "{question_labels.get(selected_column, selected_column)}" ({display_mode_general})', color='Resposta', text_auto=True)
                            fig_general.update_layout(xaxis={'categoryorder':'total descending'})
                            st.plotly_chart(fig_general, use_container_width=True)
                        elif chart_type_general == "Barra Horizontal":
                            fig_general = px.bar(resultados_generais, y='Resposta', x=display_mode_general, title=f'Distribui√ß√£o de Respostas para "{question_labels.get(selected_column, selected_column)}" ({display_mode_general})', color='Resposta', orientation='h', text_auto=True)
                            fig_general.update_layout(yaxis={'categoryorder':'total ascending'})
                            st.plotly_chart(fig_general, use_container_width=True)
                        elif chart_type_general == "Pizza":
                            fig_general = px.pie(resultados_generais, names='Resposta', values=display_mode_general, title=f'Distribui√ß√£o de Respostas para "{question_labels.get(selected_column, selected_column)}" ({display_mode_general})', hole=0.3)
                            st.plotly_chart(fig_general, use_container_width=True)
            else:
                st.info("Por favor, selecione uma quest√£o para visualizar a an√°lise.")
    else:
        st.warning("Nenhum grupo de colunas categ√≥ricas foi identificado para an√°lise. Verifique seus dados.")

    # Detalhamento por Territ√≥rio, G√™nero e Ra√ßa/Cor
    if 'selected_column' in locals() and selected_column and not ('is_numeric_column' in locals() and is_numeric_column): 
        st.markdown("---")
        st.subheader("Detalhamento por Vari√°veis Chave")
        st.write(f"Veja a distribui√ß√£o da quest√£o **'{question_labels.get(selected_column, selected_column)}'** cruzada com Territ√≥rio, G√™nero e Ra√ßa/Cor.")

        df_detail_data = None
        if selected_group == "Sentimentos e Percep√ß√µes":
            if 'ID' in df_sentiment_filtered_by_main.columns and 'ID' in df.columns:
                df_detail_data = df_sentiment_filtered_by_main[[selected_column, 'ID']].merge(
                    df[['ID', 'ADAI_CT4', 'ADAI_ID8', 'ID7']], on='ID', how='inner')
            else:
                st.warning("Para detalhamento de sentimentos, 'ID' √© necess√°rio em ambos os DataFrames.")
                df_detail_data = pd.DataFrame() 
        else:
            df_detail_data = df[[selected_column, 'ADAI_CT4', 'ADAI_ID8', 'ID7']]
        
        if df_detail_data is not None and not df_detail_data.empty:
            if 'ADAI_CT4' in df_detail_data.columns: 
                st.markdown("#### Por Territ√≥rio")
                df_cross_territory = df_detail_data[[selected_column, 'ADAI_CT4']].dropna()
                if not df_cross_territory.empty:
                    crosstab_territory = pd.crosstab(df_cross_territory[selected_column], df_cross_territory['ADAI_CT4'])
                    st.dataframe(crosstab_territory, use_container_width=True)
                    fig_territory = px.bar(crosstab_territory.reset_index().melt(id_vars=selected_column, var_name='Territ√≥rio', value_name='Contagem'), x=selected_column, y='Contagem', color='Territ√≥rio', barmode='group', title=f'Distribui√ß√£o de {question_labels.get(selected_column, selected_column)} por Territ√≥rio', text_auto=True)
                    fig_territory.update_layout(xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_territory, use_container_width=True)
                else: st.info("N√£o h√° dados para cruzar com Territ√≥rio.")

            if 'ADAI_ID8' in df_detail_data.columns: 
                st.markdown("#### Por G√™nero")
                df_cross_gender = df_detail_data[[selected_column, 'ADAI_ID8']].dropna()
                if not df_cross_gender.empty:
                    crosstab_gender = pd.crosstab(df_cross_gender[selected_column], df_cross_gender['ADAI_ID8'])
                    st.dataframe(crosstab_gender, use_container_width=True)
                    fig_gender = px.bar(crosstab_gender.reset_index().melt(id_vars=selected_column, var_name='G√™nero', value_name='Contagem'), x=selected_column, y='Contagem', color='G√™nero', barmode='group', title=f'Distribui√ß√£o de {question_labels.get(selected_column, selected_column)} por G√™nero', text_auto=True)
                    fig_gender.update_layout(xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_gender, use_container_width=True)
                else: st.info("N√£o h√° dados para cruzar com G√™nero.")

            if 'ID7' in df_detail_data.columns: 
                st.markdown("#### Por Ra√ßa/Cor")
                df_cross_race = df_detail_data[[selected_column, 'ID7']].dropna()
                if not df_cross_race.empty:
                    crosstab_race = pd.crosstab(df_cross_race[selected_column], df_cross_race['ID7'])
                    st.dataframe(crosstab_race, use_container_width=True)
                    fig_race = px.bar(crosstab_race.reset_index().melt(id_vars=selected_column, var_name='Ra√ßa/Cor', value_name='Contagem'), x=selected_column, y='Contagem', color='Ra√ßa/Cor', barmode='group', title=f'Distribui√ß√£o de {question_labels.get(selected_column, selected_column)} por Ra√ßa/Cor', text_auto=True)
                    fig_race.update_layout(xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_race, use_container_width=True)
                else: st.info("N√£o h√° dados para cruzar com Ra√ßa/Cor.")
        else:
            st.warning("N√£o h√° dados de detalhamento dispon√≠veis ap√≥s a combina√ß√£o de DataFrames.")

    # --- AN√ÅLISE AUTOM√ÅTICA DA IA ---
    st.markdown("---")
    st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
    mostrar_ia = st.toggle("Mostrar an√°lise autom√°tica da IA para esta an√°lise", value=False, key="toggle_ia_unica")
    if mostrar_ia:
        st.markdown("A IA pode gerar um resumo ou responder perguntas sobre os dados filtrados desta an√°lise.")
        if "historico_ia_unica" not in st.session_state:
            st.session_state.historico_ia_unica = []
        if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_unica"):
            with st.spinner("A IA est√° analisando os dados..."):
                total_respondents = len(df)
                if total_respondents == 0:
                    ia_response = "**N√£o h√° dados para analisar com os filtros atuais.**"
                else:
                    gender_mode = df['ADAI_ID8'].mode()[0] if not df['ADAI_ID8'].empty else 'N√£o informado'
                    race_mode = df['ID7'].mode()[0] if not df['ID7'].empty else 'N√£o informado'
                    avg_age = f"{df['Idade'].mean():.1f}" if not df['Idade'].dropna().empty else 'N/A'
                    ia_response = f"""
**Resumo dos {total_respondents} entrevistados filtrados:**
- **G√™nero mais frequente:** {gender_mode}
- **Ra√ßa/Cor mais representativa:** {race_mode}
- **Idade m√©dia:** {avg_age} anos

- **Sugest√£o:** Utilize a an√°lise cruzada para aprofundar os insights.
- **Perguntas para a IA:**  
    - Quantos entrevistados s√£o mulheres negras em Colatina?  
    - Qual o sentimento predominante sobre 'modos de vida' em Baixo Guandu?  
    - Como a renda mudou ap√≥s o rompimento para povos tradicionais?
"""
                st.session_state.historico_ia_unica.append({"pergunta": "Resumo Autom√°tico", "resposta": ia_response})
                st.markdown(ia_response)
        pergunta_livre = st.text_input("Pergunte algo para a IA sobre os dados filtrados:", key="pergunta_livre_unica")
        if st.button("Perguntar √† IA", key="perguntar_ia_unica"):
            try:
                import openai
                client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                sample = df.sample(min(len(df), 250)).to_dict(orient="records")
                user_question = f"Considere esta amostra dos dados: {sample}\nPergunta: {pergunta_livre}"
                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                )
                ia_resp = completion.choices[0].message.content
            except Exception as e:
                ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
            st.session_state.historico_ia_unica.append({"pergunta": pergunta_livre, "resposta": ia_resp})
            st.markdown("**Resposta da IA:**")
            st.write(ia_resp)
        if st.session_state.historico_ia_unica:
            with st.expander("Ver hist√≥rico de perguntas √† IA"):
                for h in st.session_state.historico_ia_unica[::-1]:
                    st.markdown(f"**Pergunta:** {h['pergunta']}")
                    st.markdown(h["resposta"])
                    st.markdown("---")

# BLOCO 2: An√°lise Cruzada de Quest√µes
elif analysis_type == "An√°lise Cruzada de Quest√µes":
    st.header("An√°lise Cruzada de Quest√µes")
    st.write("Selecione duas quest√µes para ver a rela√ß√£o entre elas.")

    if len(all_selectable_categorical_cols) >= 2:
        options_for_cross_selectbox = [("Selecione uma quest√£o", None)] + [(question_labels.get(col, col), col) for col in all_selectable_categorical_cols]
        selected_option_col1 = st.selectbox("Selecione a Quest√£o Principal (Linhas):", options_for_cross_selectbox, format_func=lambda x: x[0], key="cross_col1")
        col1_cross = selected_option_col1[1]

        options_for_col2_cross = [("Selecione uma quest√£o", None)] + [(question_labels.get(col, col), col) for col in all_selectable_categorical_cols if col != col1_cross]
        selected_option_col2 = st.selectbox("Selecione a Quest√£o para Cruzar (Colunas):", options_for_col2_cross, format_func=lambda x: x[0], key="cross_col2")
        col2_cross = selected_option_col2[1]

        if col1_cross and col2_cross:
            temp_df_cross = None
            
            # Checa onde est√£o as colunas e faz merge se necess√°rio
            if col1_cross in df.columns and col2_cross in df.columns:
                temp_df_cross = df[[col1_cross, col2_cross]]
            elif col1_cross in df_sentiment_filtered_by_main.columns and col2_cross in df_sentiment_filtered_by_main.columns:
                temp_df_cross = df_sentiment_filtered_by_main[[col1_cross, col2_cross]]
            elif 'ID' in df.columns and 'ID' in df_sentiment_filtered_by_main.columns:
                if col1_cross in df.columns and col2_cross in df_sentiment_filtered_by_main.columns:
                    temp_df_cross = df[[col1_cross, 'ID']].merge(df_sentiment_filtered_by_main[[col2_cross, 'ID']], on='ID', how='inner')
                elif col1_cross in df_sentiment_filtered_by_main.columns and col2_cross in df.columns:
                    temp_df_cross = df_sentiment_filtered_by_main[[col1_cross, 'ID']].merge(df[[col2_cross, 'ID']], on='ID', how='inner')
            
            if temp_df_cross is not None:
                df_cross = temp_df_cross.dropna()
            else:
                st.warning(f"N√£o foi poss√≠vel encontrar ou combinar as colunas '{question_labels.get(col1_cross, col1_cross)}' e '{question_labels.get(col2_cross, col2_cross)}' para cruzamento. Verifique se est√£o nos DataFrames corretos e se h√° uma coluna 'ID' para uni√£o.")
                df_cross = pd.DataFrame()

            if df_cross.empty:
                st.warning(f"N√£o h√° dados para cruzar as quest√µes '{question_labels.get(col1_cross, col1_cross)}' e '{question_labels.get(col2_cross, col2_cross)}' ap√≥s remover valores em branco.")
            else:
                st.subheader(f"Cruzamento de '{question_labels.get(col1_cross, col1_cross)}' por '{question_labels.get(col2_cross, col2_cross)}'")

                col_cross_display, col_cross_chart = st.columns(2)
                with col_cross_display:
                    cross_display_mode = st.radio("Exibir como:", ("Contagem (N√∫mero de Entrevistados)", "Porcentagem por Linha", "Porcentagem por Coluna", "Porcentagem Total"), index=0, key="cross_display_mode")
                with col_cross_chart:
                    chart_type_cross = st.radio("Tipo de Gr√°fico Cruzado:", ("Barras Empilhadas", "Barras Agrupadas"), index=0, key="chart_type_cross")

                if cross_display_mode == "Contagem (N√∫mero de Entrevistados)": crosstab_table = pd.crosstab(df_cross[col1_cross], df_cross[col2_cross])
                elif cross_display_mode == "Porcentagem por Linha": crosstab_table = pd.crosstab(df_cross[col1_cross], df_cross[col2_cross], normalize='index').mul(100).round(2)
                elif cross_display_mode == "Porcentagem por Coluna": crosstab_table = pd.crosstab(df_cross[col1_cross], df_cross[col2_cross], normalize='columns').mul(100).round(2)
                elif cross_display_mode == "Porcentagem Total": crosstab_table = pd.crosstab(df_cross[col1_cross], df_cross[col2_cross], normalize='all').mul(100).round(2)

                st.dataframe(crosstab_table, use_container_width=True)

                csv_data_cross = crosstab_table.to_csv().encode('utf-8')
                st.download_button(label="Baixar Tabela como CSV", data=csv_data_cross, file_name=f"{col1_cross}_x_{col2_cross}_cruzamento.csv", mime="text/csv", key=f"download_csv_cross_{col1_cross}_{col2_cross}")
                excel_buffer_cross = io.BytesIO()
                crosstab_table.to_excel(excel_buffer_cross, engine='xlsxwriter')
                excel_buffer_cross.seek(0)
                st.download_button(label="Baixar Tabela como Excel", data=excel_buffer_cross.getvalue(), file_name=f"{col1_cross}_x_{col2_cross}_cruzamento.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet", key=f"download_excel_cross_{col1_cross}_{col2_cross}")
                st.markdown("---")
                st.info("Para baixar o gr√°fico, clique com o bot√£o direito sobre ele e selecione 'Salvar imagem como...' ou 'Baixar imagem'.")

                st.subheader("Visualiza√ß√£o Cruzada")
                plot_df = df_cross.groupby([col1_cross, col2_cross]).size().reset_index(name='Contagem')

                if chart_type_cross == "Barras Empilhadas":
                    fig_cross = px.bar(plot_df, x=col1_cross, y='Contagem', color=col2_cross, title=f'Distribui√ß√£o de {question_labels.get(col1_cross, col1_cross)} por {question_labels.get(col2_cross, col2_cross)} (Empilhado)', text_auto=True)
                    fig_cross.update_layout(xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_cross, use_container_width=True)
                elif chart_type_cross == "Barras Agrupadas":
                    fig_cross = px.bar(plot_df, x=col1_cross, y='Contagem', color=col2_cross, barmode='group', title=f'Distribui√ß√£o de {question_labels.get(col1_cross, col1_cross)} por {question_labels.get(col2_cross, col2_cross)} (Agrupado)', text_auto=True)
                    fig_cross.update_layout(xaxis={'categoryorder':'total descending'})
                    st.plotly_chart(fig_cross, use_container_width=True)
                
        else:
            st.info("Por favor, selecione duas quest√µes para realizar a an√°lise cruzada.")
    else:
        st.warning("N√£o h√° colunas categ√≥ricas suficientes para realizar a an√°lise cruzada (m√≠nimo de 2).")

    # --- AN√ÅLISE AUTOM√ÅTICA DA IA ---
    st.markdown("---")
    st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
    mostrar_ia = st.toggle("Mostrar an√°lise autom√°tica da IA para esta an√°lise", value=False, key="toggle_ia_cruzada")
    if mostrar_ia:
        st.markdown("A IA pode gerar insights autom√°ticos ou responder perguntas sobre o cruzamento apresentado acima.")
        if "historico_ia_cruzada" not in st.session_state:
            st.session_state.historico_ia_cruzada = []
        if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_cruzada"):
            with st.spinner("A IA est√° analisando os dados cruzados..."):
                if 'df_cross' in locals() and not df_cross.empty:
                    n = len(df_cross)
                    top_linhas = df_cross[col1_cross].mode()[0] if not df_cross[col1_cross].empty else 'N/A'
                    top_colunas = df_cross[col2_cross].mode()[0] if not df_cross[col2_cross].empty else 'N/A'
                    ia_resp = f"""
**Resumo do cruzamento:**
- Total de pares de respostas: {n}
- Valor mais frequente para "{question_labels.get(col1_cross, col1_cross)}": {top_linhas}
- Valor mais frequente para "{question_labels.get(col2_cross, col2_cross)}": {top_colunas}

- **Sugest√£o:** Observe as combina√ß√µes de respostas com maior frequ√™ncia para identificar padr√µes relevantes.
"""
                else:
                    ia_resp = "N√£o h√° dados cruzados suficientes para an√°lise com a IA."
                st.session_state.historico_ia_cruzada.append({"pergunta": "Resumo Autom√°tico", "resposta": ia_resp})
                st.markdown(ia_resp)
        pergunta_livre = st.text_input("Pergunte algo para a IA sobre o cruzamento:", key="pergunta_livre_cruzada")
        if st.button("Perguntar √† IA", key="perguntar_ia_cruzada"):
            try:
                import openai
                client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                sample = df_cross.sample(min(len(df_cross), 250)).to_dict(orient="records")
                user_question = f"Considere esta amostra do cruzamento de duas colunas: {sample}\nPergunta: {pergunta_livre}"
                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                )
                ia_resp = completion.choices[0].message.content
            except Exception as e:
                ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
            st.session_state.historico_ia_cruzada.append({"pergunta": pergunta_livre, "resposta": ia_resp})
            st.markdown("**Resposta da IA:**")
            st.write(ia_resp)
        if st.session_state.historico_ia_cruzada:
            with st.expander("Ver hist√≥rico de perguntas √† IA"):
                for h in st.session_state.historico_ia_cruzada[::-1]:
                    st.markdown(f"**Pergunta:** {h['pergunta']}")
                    st.markdown(h["resposta"])
                    st.markdown("---")

# BLOCO 3: Visualiza√ß√£o por Mapa 
elif analysis_type == "Visualiza√ß√£o por Mapa":
    st.header("Visualiza√ß√£o por Mapa")
    st.info("Este mapa exibe a distribui√ß√£o espacial dos munic√≠pios onde h√° respondentes. O tamanho do c√≠rculo indica o n√∫mero de respondentes.")
    st.markdown("---")

    # Posi√ß√£o central do ES
    center = [-19.5, -40.5]

    # --- Cria DataFrame de munic√≠pios e total de respondentes
    df_map_data = df.groupby('ADAI_CT4').size().reset_index(name='Total Respondentes')
    df_map_data = df_map_data.rename(columns={'ADAI_CT4': 'nome'}) 

    # Merge com lat/lon
    lat_lon_df = pd.read_csv('data/municipios_es_lat_lon.csv', sep=';', encoding='utf-8')
    df_map_data = df_map_data.merge(lat_lon_df, on='nome', how='left')

    # Total de homens/mulheres por munic√≠pio
    sexo_counts = (
        df[df['ADAI_ID8'].isin(['Homem', 'Mulher'])]
        .groupby(['ADAI_CT4', 'ADAI_ID8']).size().unstack(fill_value=0)
        .reset_index().rename(columns={'ADAI_CT4': 'nome'})
    )
    df_map_data = df_map_data.merge(sexo_counts, on='nome', how='left')

    df_map_data['Pct_Homens'] = (df_map_data.get('Homem', 0) / df_map_data['Total Respondentes'] * 100).round(1)
    df_map_data['Pct_Mulheres'] = (df_map_data.get('Mulher', 0) / df_map_data['Total Respondentes'] * 100).round(1)

    # Profiss√£o mais comum por munic√≠pio
    profissao_pred = (
        df.groupby('ADAI_CT4')['ADAI_ID12']
        .agg(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else None)
        .reset_index().rename(columns={'ADAI_CT4': 'nome', 'ADAI_ID12': 'Profissao_Predominante'})
    )
    df_map_data = df_map_data.merge(profissao_pred, on='nome', how='left')

    # Escolaridade mais comum
    escolaridade_pred = (
        df.groupby('ADAI_CT4')['ID11']
        .agg(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else None)
        .reset_index().rename(columns={'ADAI_CT4': 'nome', 'ID11': 'Escolaridade_Predominante'})
    )
    df_map_data = df_map_data.merge(escolaridade_pred, on='nome', how='left')

    # Religi√£o mais comum
    religiao_pred = (
        df.groupby('ADAI_CT4')['ID12']
        .agg(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else None)
        .reset_index().rename(columns={'ADAI_CT4': 'nome', 'ID12': 'Religiao_Predominante'})
    )
    df_map_data = df_map_data.merge(religiao_pred, on='nome', how='left')

    # Povo tradicional: % de respondentes por munic√≠pio
    povo_pct = (
        df[df['PCT0'] == 'Sim']
        .groupby('ADAI_CT4').size() / df.groupby('ADAI_CT4').size()
    ).mul(100).round(1).reset_index(name='Pct_Povo_Tradicional')
    povo_pct = povo_pct.rename(columns={'ADAI_CT4': 'nome'})
    df_map_data = df_map_data.merge(povo_pct, on='nome', how='left')

    # Defici√™ncia: % de respondentes com defici√™ncia
    if 'Deficiencia' in df.columns:
        def_pct = (
            df[df['Deficiencia'] == 'Sim']
            .groupby('ADAI_CT4').size() / df.groupby('ADAI_CT4').size()
        ).mul(100).round(1).reset_index(name='Pct_Deficiencia')
        def_pct = def_pct.rename(columns={'ADAI_CT4': 'nome'})
        df_map_data = df_map_data.merge(def_pct, on='nome', how='left')
    else:
        df_map_data['Pct_Deficiencia'] = None

    # Ra√ßa/cor: mais comum por munic√≠pio
    raca_pred = (
        df.groupby('ADAI_CT4')['ID7']
        .agg(lambda x: x.value_counts().idxmax() if not x.value_counts().empty else None)
        .reset_index().rename(columns={'ADAI_CT4': 'nome', 'ID7': 'Raca_Predominante'})
    )
    df_map_data = df_map_data.merge(raca_pred, on='nome', how='left')

    # --- Remover colunas duplicadas de 'nome'
    df_map_data = df_map_data.loc[:, ~df_map_data.columns.duplicated()]

    # Set dos munic√≠pios com respostas
    municipios_com_respostas = set(df_map_data['nome'])

    # Fun√ß√£o melhorada para popup: mostra mais detalhes e emojis
    def make_popup(row):
        return folium.Popup(f"""
            <b>{row['nome']}</b><br>
            üë§ <b>Total respondentes:</b> {row['Total Respondentes']}<br>
            üë© <b>Mulheres:</b> {row.get('Mulher', 0)} ({row.get('Pct_Mulheres', 0)}%)<br>
            üë® <b>Homens:</b> {row.get('Homem', 0)} ({row.get('Pct_Homens', 0)}%)<br>
            üßë‚Äçü¶± <b>Ra√ßa predominante:</b> {row.get('Raca_Predominante', 'n/d')}<br>
            üéì <b>Escolaridade predominante:</b> {row.get('Escolaridade_Predominante', 'n/d')}<br>
            üíº <b>Profiss√£o predominante:</b> {row.get('Profissao_Predominante', 'n/d')}<br>
            üôè <b>Religi√£o predominante:</b> {row.get('Religiao_Predominante', 'n/d')}<br>
            üå± <b>% Povo tradicional:</b> {row.get('Pct_Povo_Tradicional', 0)}%<br>
            ‚ôø <b>% com defici√™ncia:</b> {row.get('Pct_Deficiencia', 'n/d')}%
        """, max_width=350)

    # --- Mapa Folium dos limites do ES
    m = folium.Map(location=center, zoom_start=7, tiles='cartodbpositron')

    for feature in estados_geojson['features']:
        nome_municipio_geojson = feature['properties'].get('name')
        if nome_municipio_geojson in municipios_com_respostas:
            color = '#ffe74c'
            fill_opacity = 0.8
            row = df_map_data[df_map_data['nome'] == nome_municipio_geojson].iloc[0]
            popup = make_popup(row)
        else:
            color = '#c0c0c0'
            fill_opacity = 0.2
            popup = None

        folium.GeoJson(
            feature,
            style_function=lambda x, color=color, fill_opacity=fill_opacity: {
                'fillColor': color,
                'color': 'black',
                'weight': 1,
                'fillOpacity': fill_opacity
            },
            tooltip=nome_municipio_geojson,
            popup=popup
        ).add_to(m)

   # folium_static(m, width=900, height=650)

    # --- Mapa Plotly dos pontos
    if 'lat' in df_map_data.columns and 'lon' in df_map_data.columns and not df_map_data[['lat', 'lon']].isna().all().all():
        try:
            lat_center = df_map_data["lat"].mean()
            lon_center = df_map_data["lon"].mean()
            fig_map = px.scatter_mapbox(
                df_map_data,
                lat="lat",
                lon="lon",
                size="Total Respondentes",
                color="Total Respondentes",
                color_continuous_scale=px.colors.sequential.Viridis,
                hover_name="nome",
                hover_data={
                    "Total Respondentes": True,
                    "Mulher": True,
                    "Homem": True,
                    "Pct_Mulheres": True,
                    "Pct_Homens": True,
                    "Profissao_Predominante": True,
                    "Escolaridade_Predominante": True,
                    "Religiao_Predominante": True,
                    "Pct_Povo_Tradicional": True,
                    "Pct_Deficiencia": True,
                    "Raca_Predominante": True,
                    "lat": False, "lon": False
                },
                mapbox_style="carto-positron",
                zoom=6,
                center={"lat": lat_center, "lon": lon_center},
                title="Total de Respondentes por Munic√≠pio (Mapa de Pontos)"
            )
            fig_map.update_layout(margin={"r":0,"t":0,"l":0,"b":0}, height=600)
            st.plotly_chart(fig_map, use_container_width=True)
        except Exception as e:
            st.error(f"Erro ao gerar o mapa Plotly: {e}")
    else:
        st.warning("N√£o h√° coordenadas (lat/lon) dos munic√≠pios no DataFrame para plotar pontos no mapa. Exibindo apenas a tabela.")

    # --- Exibe tabela e download
    st.markdown("#### Detalhes por Munic√≠pio (Mapa)")
    st.dataframe(df_map_data[['nome', 'Total Respondentes', 'Homem', 'Mulher', 'Pct_Mulheres', 'Profissao_Predominante',
                         'Escolaridade_Predominante', 'Religiao_Predominante', 'Pct_Povo_Tradicional',
                         'Pct_Deficiencia', 'Raca_Predominante']], use_container_width=True)
    st.download_button("Baixar Tabela Munic√≠pios", df_map_data.to_csv(index=False), file_name="municipios_respondentes.csv")

    # --- AN√ÅLISE AUTOM√ÅTICA DA IA ---
    st.markdown("---")
    st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
    mostrar_ia = st.toggle("Mostrar an√°lise autom√°tica da IA para o mapa", value=False, key="toggle_ia_mapa")
    st.markdown("---")
    if mostrar_ia:
        st.markdown("A IA pode gerar um resumo ou responder perguntas sobre os munic√≠pios e vari√°veis deste mapa.")
        if "historico_ia_mapa" not in st.session_state:
            st.session_state.historico_ia_mapa = []
        if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_mapa"):
            with st.spinner("A IA est√° analisando a distribui√ß√£o geogr√°fica..."):
                n = len(df_map_data)
                top_cidade = df_map_data.sort_values('Total Respondentes', ascending=False).iloc[0] if n > 0 else None
                if n == 0 or top_cidade is None:
                    ia_response = "**N√£o h√° dados geogr√°ficos para an√°lise com os filtros atuais.**"
                else:
                    ia_response = f"""
**Resumo da distribui√ß√£o espacial:**
- **Total de munic√≠pios com respondentes:** {n}
- **Munic√≠pio com mais respondentes:** {top_cidade['nome']} ({top_cidade['Total Respondentes']} pessoas)
- **% m√©dia de mulheres:** {df_map_data['Pct_Mulheres'].mean():.1f}%
- **% m√©dia de povos tradicionais:** {df_map_data['Pct_Povo_Tradicional'].mean():.1f}%
- **% m√©dia com defici√™ncia:** {df_map_data['Pct_Deficiencia'].mean():.1f}%

- **Sugest√£o:** Clique sobre um munic√≠pio no mapa para detalhes e use filtros para comparar perfis.
"""
                st.session_state.historico_ia_mapa.append({"pergunta": "Resumo Autom√°tico", "resposta": ia_response})
                st.markdown(ia_response)
        pergunta_livre = st.text_input("Pergunte algo para a IA sobre os munic√≠pios ou o mapa:", key="pergunta_livre_mapa")
        if st.button("Perguntar √† IA", key="perguntar_ia_mapa"):
            try:
                import openai
                client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                sample = df_map_data.sample(min(len(df_map_data), 80)).to_dict(orient="records")
                user_question = f"Considere esta amostra dos dados de munic√≠pios: {sample}\nPergunta: {pergunta_livre}"
                completion = client.chat.completions.create(
                    model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                )
                ia_resp = completion.choices[0].message.content
            except Exception as e:
                ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
            st.session_state.historico_ia_mapa.append({"pergunta": pergunta_livre, "resposta": ia_resp})
            st.markdown("**Resposta da IA:**")
            st.write(ia_resp)
        if st.session_state.historico_ia_mapa:
            with st.expander("Ver hist√≥rico de perguntas √† IA"):
                for h in st.session_state.historico_ia_mapa[::-1]:
                    st.markdown(f"**Pergunta:** {h['pergunta']}")
                    st.markdown(h["resposta"])
                    st.markdown("---")


# BLOCO 4: An√°lise de Sentimento por Tema
elif analysis_type == "An√°lise de Sentimento por Tema":
    st.header("An√°lise de Sentimento por Tema")
    st.markdown("Explore os sentimentos e emo√ß√µes expressos nas respostas de texto livre para diferentes t√≥picos.")

    current_df_sentiment = df_sentiment_filtered_by_main

    # --- Op√ß√£o de gr√°fico
    chart_type = st.radio("Tipo de gr√°fico:", ["Pizza", "Barras"], horizontal=True, key="sentiment_chart_type")

    # Sentiment columns (ajuste conforme seus dados reais)
    sentiment_text_columns = {
        'PCT5.1_Sentimento_Geral': 'Perdas/Modos de Vida (Geral)',
        'PCT5.1_Sentimento_Satisfacao': 'Perdas/Modos de Vida (Satisfa√ß√£o)',
        'PCT5.1_Sentimento_Emocao': 'Perdas/Modos de Vida (Emo√ß√£o)',
        'PCT5.1_Sentimento_Justificativa': 'Perdas/Modos de Vida (Trechos Chave)',
        # ... [adicione outros mapeamentos conforme seu dicion√°rio]
    }
    available_sentiment_cols = {k: v for k, v in sentiment_text_columns.items() if k in current_df_sentiment.columns}

    if not available_sentiment_cols:
        st.warning("Nenhuma coluna de sentimento encontrada.")
    else:
        selected_sentiment_display_type = st.radio(
            "Visualizar por:",
            ["Sentimento Geral", "Satisfa√ß√£o", "Emo√ß√£o", "Trechos Chave"],
            key="sentiment_display_type"
        )

        filtered_sentiment_options_for_selectbox = {}
        for col_code, col_label in available_sentiment_cols.items():
            if selected_sentiment_display_type == "Sentimento Geral" and col_code.endswith('_Sentimento_Geral'):
                filtered_sentiment_options_for_selectbox[col_code] = col_label
            elif selected_sentiment_display_type == "Satisfa√ß√£o" and col_code.endswith('_Sentimento_Satisfacao'):
                filtered_sentiment_options_for_selectbox[col_code] = col_label
            elif selected_sentiment_display_type == "Emo√ß√£o" and col_code.endswith('_Sentimento_Emocao'):
                filtered_sentiment_options_for_selectbox[col_code] = col_label
            elif selected_sentiment_display_type == "Trechos Chave" and col_code.endswith('_Sentimento_Justificativa'):
                filtered_sentiment_options_for_selectbox[col_code] = col_label

        if not filtered_sentiment_options_for_selectbox:
            st.info(f"Nenhum dado de '{selected_sentiment_display_type}' dispon√≠vel.")
        else:
            selected_sentiment_topic_code = st.selectbox(
                f"Selecione a pergunta para analisar {selected_sentiment_display_type}:",
                list(filtered_sentiment_options_for_selectbox.keys()),
                format_func=lambda x: filtered_sentiment_options_for_selectbox[x],
                key="sentiment_topic_code_selector"
            )

            # S√≥ daqui para baixo pode acessar selected_sentiment_topic_code!
            if selected_sentiment_topic_code:
                # ----- Tudo protegido! -----
                total = current_df_sentiment[selected_sentiment_topic_code].notna().sum()
                sentiment_counts_abs = current_df_sentiment[selected_sentiment_topic_code].value_counts().reset_index()
                sentiment_counts_abs.columns = ['Categoria', 'Quantidade']
                sentiment_counts_abs['Porcentagem (%)'] = (sentiment_counts_abs['Quantidade']/total*100).round(2)
                st.markdown("##### Tabela de Distribui√ß√£o dos Sentimentos")
                st.dataframe(sentiment_counts_abs, use_container_width=True)

                st.download_button(
                    "Baixar distribui√ß√£o (CSV)",
                    sentiment_counts_abs.to_csv(index=False),
                    file_name=f"sentimentos_{selected_sentiment_topic_code}.csv"
                )

                # --- Gr√°fico
                if chart_type == "Pizza":
                    fig_sentiment = px.pie(
                        sentiment_counts_abs,
                        names='Categoria',
                        values='Quantidade',
                        title=f'Distribui√ß√£o de {filtered_sentiment_options_for_selectbox[selected_sentiment_topic_code]}',
                        hole=0.3
                    )
                else:  # Barras
                    fig_sentiment = px.bar(
                        sentiment_counts_abs.sort_values("Quantidade", ascending=False),
                        x='Categoria',
                        y='Quantidade',
                        text='Porcentagem (%)',
                        title=f'Distribui√ß√£o de {filtered_sentiment_options_for_selectbox[selected_sentiment_topic_code]}'
                    )
                    fig_sentiment.update_layout(xaxis_title="", yaxis_title="Quantidade")
                st.plotly_chart(fig_sentiment, use_container_width=True)

                # --- Nuvem de palavras (opcional)
                original_col_prefix = selected_sentiment_topic_code.rsplit('_', 2)[0]
                justification_col_name = f"{original_col_prefix}_Sentimento_Justificativa"
                mostrar_nuvem = st.checkbox("Mostrar nuvem de palavras dos trechos chave (experimental)")
                if mostrar_nuvem:
                    try:
                        from wordcloud import WordCloud
                        import matplotlib.pyplot as plt
                        textos = current_df_sentiment[justification_col_name].dropna().str.cat(sep=' ')
                        wordcloud = WordCloud(width=800, height=300, background_color='white').generate(textos)
                        fig_wc, ax = plt.subplots(figsize=(10,3))
                        ax.imshow(wordcloud, interpolation='bilinear')
                        ax.axis('off')
                        st.pyplot(fig_wc)
                    except Exception as e:
                        st.warning(f"N√£o foi poss√≠vel gerar a nuvem de palavras: {e}")

                # --- Exemplos de Trechos Chave + download
                if justification_col_name in current_df_sentiment.columns:
                    all_samples = current_df_sentiment[justification_col_name].dropna().tolist()
                    st.download_button(
                        "Baixar trechos chave (TXT)",
                        "\n".join(all_samples),
                        file_name=f"trechos_{selected_sentiment_topic_code}.txt"
                    )
                else:
                    st.info("N√£o h√° coluna de trechos chave para esta sele√ß√£o.")

                # --- An√°lise autom√°tica da IA
                st.markdown("---")
                st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
                mostrar_ia = st.toggle("Mostrar an√°lise da IA para os sentimentos", value=False, key="toggle_ia_sentimentos")
                st.markdown("---")
                if mostrar_ia:
                    st.markdown("A IA pode gerar um resumo autom√°tico ou responder perguntas sobre os sentimentos.")
                    if "historico_ia_sentimentos" not in st.session_state:
                        st.session_state.historico_ia_sentimentos = []
                    if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_sent"):
                        with st.spinner("A IA est√° analisando os sentimentos..."):
                            n = total
                            top = sentiment_counts_abs.iloc[0] if n > 0 else None
                            if n == 0 or top is None:
                                ia_response = "**N√£o h√° dados para an√°lise com os filtros atuais.**"
                            else:
                                ia_response = f"""
**Resumo dos sentimentos analisados:**
- **Total de exemplos analisados:** {n}
- **Sentimento/Categoria mais citada:** {top['Categoria']} ({top['Quantidade']} respostas, {top['Porcentagem (%)']}%)
- **Distribui√ß√£o geral:** {dict(zip(sentiment_counts_abs['Categoria'], sentiment_counts_abs['Porcentagem (%)']))}
- **Sugest√£o:** Veja exemplos reais abaixo ou filtre por t√≥picos para aprofundar.
"""
                            st.session_state.historico_ia_sentimentos.append({"pergunta": "Resumo Autom√°tico", "resposta": ia_response})
                            st.markdown(ia_response)
                    pergunta_livre = st.text_input("Pergunte algo para a IA sobre os sentimentos ou as cita√ß√µes:", key="pergunta_livre_sent")
                    if st.button("Perguntar √† IA", key="perguntar_ia_sent"):
                        try:
                            import openai
                            client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                            sample = current_df_sentiment[[selected_sentiment_topic_code, justification_col_name]].dropna().sample(min(40, len(current_df_sentiment))).to_dict(orient="records")
                            user_question = f"Considere esta amostra dos sentimentos e justificativas: {sample}\nPergunta: {pergunta_livre}"
                            completion = client.chat.completions.create(
                                model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                            )
                            ia_resp = completion.choices[0].message.content
                        except Exception as e:
                            ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
                        st.session_state.historico_ia_sentimentos.append({"pergunta": pergunta_livre, "resposta": ia_resp})
                        st.markdown("**Resposta da IA:**")
                        st.write(ia_resp)
                    if st.session_state.historico_ia_sentimentos:
                        with st.expander("Ver hist√≥rico de perguntas √† IA"):
                            for h in st.session_state.historico_ia_sentimentos[::-1]:
                                st.markdown(f"**Pergunta:** {h['pergunta']}")
                                st.markdown(h["resposta"])
                                st.markdown("---")


# BLOCO 5: An√°lise de Lacunas (Antes vs. Depois)
elif analysis_type == "An√°lise de Lacunas (Antes vs. Depois)":
    st.header("An√°lise de Lacunas: Antes vs. Depois do Rompimento")
    st.markdown("Compare a situa√ß√£o dos respondentes antes e depois do rompimento da barragem em √°reas chave para identificar as principais lacunas e impactos.")

    gap_analysis_pairs = {
        "Acesso a Programas Sociais (ID13/ID14)": ('ID13', 'ID14'),
        "Acesso √† √Ågua do Rio Doce (AQA1/AQA2)": ('AQA1', 'AQA2'),
        "Exercia Atividade Remunerada (AER1/ARF1.1)": ('AER1', 'ARF1.1'), 
    }
    available_gap_pairs = {k:v for k,v in gap_analysis_pairs.items() if v[0] in df.columns and v[1] in df.columns}

    if not available_gap_pairs:
        st.warning("Nenhum par de perguntas 'Antes/Depois' encontrado para an√°lise de lacunas.")
    else:
        selected_gap_pair_label = st.selectbox(
            "Selecione a Dimens√£o para An√°lise de Lacunas:",
            list(available_gap_pairs.keys()),
            key="gap_pair_selector"
        )

        if selected_gap_pair_label:
            col_antes, col_depois = available_gap_pairs[selected_gap_pair_label]

            st.subheader(f"Comparativo: {question_labels.get(col_antes, col_antes)} vs. {question_labels.get(col_depois, col_depois)}")
            df_gap = df[[col_antes, col_depois]].dropna()

            if not df_gap.empty:
                counts_antes = df_gap[col_antes].value_counts(normalize=True).mul(100).round(2).reset_index()
                counts_antes.columns = ['Resposta', 'Porcentagem (%)']
                counts_antes['Per√≠odo'] = 'Antes do Rompimento'

                counts_depois = df_gap[col_depois].value_counts(normalize=True).mul(100).round(2).reset_index()
                counts_depois.columns = ['Resposta', 'Porcentagem (%)']
                counts_depois['Per√≠odo'] = 'Depois do Rompimento'

                combined_counts = pd.concat([counts_antes, counts_depois])

                fig_gap = px.bar(
                    combined_counts,
                    x='Resposta',
                    y='Porcentagem (%)',
                    color='Per√≠odo',
                    barmode='group',
                    title=f'Comparativo de "{selected_gap_pair_label}" Antes e Depois do Rompimento',
                    text_auto=True
                )
                fig_gap.update_layout(xaxis={'categoryorder':'total descending'})
                st.plotly_chart(fig_gap, use_container_width=True)

                st.markdown("#### Tabela Comparativa (Porcentagens)")
                crosstab_gap = pd.crosstab(df_gap[col_antes], df_gap[col_depois], normalize='index').mul(100).round(2)
                st.dataframe(crosstab_gap, use_container_width=True)
                st.info("A tabela acima mostra a porcentagem de respondentes de uma categoria 'Antes' que ca√≠ram em cada categoria 'Depois'.")

                kpi_text = ""
                if 'Sim' in counts_antes['Resposta'].values and 'Sim' in counts_depois['Resposta'].values:
                    perc_antes_sim = counts_antes[counts_antes['Resposta'] == 'Sim']['Porcentagem (%)'].iloc[0]
                    perc_depois_sim = counts_depois[counts_depois['Resposta'] == 'Sim']['Porcentagem (%)'].iloc[0]
                    kpi_text = (
                        f"**KPI:** A porcentagem de respondentes que afirmam '{selected_gap_pair_label}' (resposta 'Sim') mudou de **{perc_antes_sim:.1f}%** antes para **{perc_depois_sim:.1f}%** depois do rompimento. "
                        f"Isso representa uma **mudan√ßa de {perc_depois_sim - perc_antes_sim:.1f} pontos percentuais**."
                    )
                    st.markdown(kpi_text)

                # --- IA: Resumo Autom√°tico
                st.markdown("---")
                st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
                mostrar_ia = st.toggle("Mostrar an√°lise autom√°tica da IA para esta lacuna", value=False, key="toggle_ia_gap")
                if mostrar_ia:
                    st.markdown("---")
                    st.markdown("A IA pode gerar um resumo interpretando as mudan√ßas entre antes e depois ou responder perguntas livres.")
                    if "historico_ia_gap" not in st.session_state:
                        st.session_state.historico_ia_gap = []
                    if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_gap"):
                        with st.spinner("A IA est√° analisando os dados..."):
                            resumo = f"""
**Resumo IA - An√°lise Antes vs. Depois:**
- **Dimens√£o:** {selected_gap_pair_label}
- **Principais mudan√ßas:** {kpi_text if kpi_text else "Veja as tabelas acima."}
- **Distribui√ß√£o Antes:** {dict(zip(counts_antes['Resposta'], counts_antes['Porcentagem (%)']))}
- **Distribui√ß√£o Depois:** {dict(zip(counts_depois['Resposta'], counts_depois['Porcentagem (%)']))}
"""
                            st.session_state.historico_ia_gap.append({"pergunta": "Resumo Autom√°tico", "resposta": resumo})
                            st.markdown(resumo)
                    pergunta_livre = st.text_input("Pergunte algo √† IA sobre essa lacuna:", key="pergunta_livre_gap")
                    if st.button("Perguntar √† IA", key="perguntar_ia_gap"):
                        try:
                            import openai
                            client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                            sample = df_gap.sample(min(40, len(df_gap))).to_dict(orient="records")
                            user_question = f"Considere esta amostra dos dados antes/depois: {sample}\nPergunta: {pergunta_livre}"
                            completion = client.chat.completions.create(
                                model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                            )
                            ia_resp = completion.choices[0].message.content
                        except Exception as e:
                            ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
                        st.session_state.historico_ia_gap.append({"pergunta": pergunta_livre, "resposta": ia_resp})
                        st.markdown("**Resposta da IA:**")
                        st.write(ia_resp)
                    if st.session_state.historico_ia_gap:
                        with st.expander("Ver hist√≥rico de perguntas √† IA (lacunas)"):
                            for h in st.session_state.historico_ia_gap[::-1]:
                                st.markdown(f"**Pergunta:** {h['pergunta']}")
                                st.markdown(h["resposta"])
                                st.markdown("---")
            else:
                st.warning("N√£o h√° dados v√°lidos para este par de an√°lise de lacunas com os filtros atuais.")
        else:
            st.info("Por favor, selecione uma dimens√£o para a an√°lise de lacunas.")

# BLOCO 6: An√°lise de Vulnerabilidade
elif analysis_type == "An√°lise de Vulnerabilidade":
    st.header("An√°lise de Vulnerabilidade")
    st.markdown("Explore como diferentes grupos demogr√°ficos foram impactados ou percebem a situa√ß√£o, identificando potenciais vulnerabilidades.")

    vulnerability_vars = {
        'ID7': 'Ra√ßa/Cor',
        'ADAI_ID8': 'G√™nero',
        'ID10': 'Pessoa com Defici√™ncia',
        'PCT0': 'Povo/Comunidade Tradicional',
    }

    impact_vars = {
        'PCT5.1_Sentimento_Geral': 'Perdas/Modos de Vida (Sentimento Geral)',
        'PCT5.1_Sentimento_Emocao': 'Perdas/Modos de Vida (Emo√ß√£o)',
        'PC1.1.8.1_Sentimento_Satisfacao': 'Sugest√µes Repara√ß√£o (Satisfa√ß√£o)',
        'ADAI_PC2_Sentimento_Geral': 'Avalia√ß√£o Participa√ß√£o (Sentimento Geral)',
        'ARF3.1': 'Perda de Renda (Comprovada)', 
        'DF1': 'D√≠vida Contra√≠da/Aumentada',
        'SA1': 'Comprometimento Qualidade Alimentos',
        'CCS7': 'Aumento Gastos Sa√∫de',
    }
    
    available_impact_vars = {k:v for k,v in impact_vars.items() if k in df.columns or k in df_sentiment.columns}

    if not available_impact_vars:
        st.warning("Nenhuma vari√°vel de impacto encontrada para an√°lise de vulnerabilidade.")
    else:
        selected_v_var = st.selectbox(
            "Selecione a Vari√°vel Demogr√°fica/Vulnerabilidade:",
            list(vulnerability_vars.keys()),
            format_func=lambda x: vulnerability_vars[x],
            key="v_var_selector"
        )

        selected_impact_var = st.selectbox(
            "Selecione a Vari√°vel de Impacto:",
            list(available_impact_vars.keys()),
            format_func=lambda x: available_impact_vars[x],
            key="impact_var_selector"
        )

        if selected_v_var and selected_impact_var:
            st.subheader(f"Impacto de '{vulnerability_vars.get(selected_v_var, selected_v_var)}' na '{impact_vars.get(selected_impact_var, selected_impact_var)}'")

            # L√≥gica de cruzamento (robusta)
            if selected_impact_var in df_sentiment.columns:  # Se a vari√°vel de impacto √© de sentimento
                if selected_v_var in df.columns and 'ID' in df.columns and 'ID' in df_sentiment_filtered_by_main.columns:
                    df_vulnerability_analysis = df_sentiment_filtered_by_main[[selected_impact_var, 'ID']].merge(
                        df[[selected_v_var, 'ID']], on='ID', how='inner'
                    ).dropna()
                else:
                    st.warning("N√£o foi poss√≠vel cruzar a vari√°vel de sentimento com a demogr√°fica. IDs ausentes ou vari√°veis n√£o encontradas.")
                    df_vulnerability_analysis = pd.DataFrame()
            elif selected_impact_var in df.columns:
                df_vulnerability_analysis = df[[selected_v_var, selected_impact_var]].dropna()
            else:
                st.warning("Vari√°vel de impacto n√£o encontrada em nenhum dos DataFrames carregados.")
                df_vulnerability_analysis = pd.DataFrame()
            
            if not df_vulnerability_analysis.empty:
                crosstab_v = pd.crosstab(df_vulnerability_analysis[selected_v_var], df_vulnerability_analysis[selected_impact_var], normalize='index').mul(100).round(2)
                st.dataframe(crosstab_v, use_container_width=True)

                fig_v = px.bar(
                    crosstab_v.reset_index().melt(id_vars=selected_v_var, var_name='Impacto', value_name='Porcentagem (%)'),
                    x=selected_v_var,
                    y='Porcentagem (%)',
                    color='Impacto',
                    barmode='group',
                    title=f'Porcentagem de Respostas para "{impact_vars.get(selected_impact_var, selected_impact_var)}" por "{vulnerability_vars.get(selected_v_var, selected_v_var)}"',
                    text_auto=True
                )
                fig_v.update_layout(xaxis={'categoryorder':'total descending'})
                st.plotly_chart(fig_v, use_container_width=True)

                # --- Insights autom√°ticos simples
                st.markdown("#### Insights de Vulnerabilidade (Exemplo):")
                if selected_v_var == 'ID7' and selected_impact_var == 'PCT5.1_Sentimento_Geral':
                    if 'Muito Negativo' in crosstab_v.columns:
                        st.markdown(f"**Dados Concretos:** A an√°lise mostra que entre os grupos raciais, **{crosstab_v['Muito Negativo'].idxmax()}** teve a maior porcentagem de sentimento 'Muito Negativo' sobre perdas e modos de vida, com **{crosstab_v['Muito Negativo'].max():.1f}%** dos respondentes desse grupo expressando esse sentimento. Em contraste, **{crosstab_v['Muito Negativo'].idxmin()}** teve a menor porcentagem, com **{crosstab_v['Muito Negativo'].min():.1f}%**.")

                if selected_v_var == 'ID10' and selected_impact_var == 'DF1':
                    if 'Sim' in crosstab_v.columns:
                        pcd_sim_divida = crosstab_v.loc['Sim', 'Sim'] if 'Sim' in crosstab_v.index and 'Sim' in crosstab_v.columns else 0
                        nao_pcd_sim_divida = crosstab_v.loc['N√£o', 'Sim'] if 'N√£o' in crosstab_v.index and 'Sim' in crosstab_v.columns else 0
                        st.markdown(f"**Dados Concretos:** Entre os respondentes, **{pcd_sim_divida:.1f}%** das pessoas com defici√™ncia reportaram ter contra√≠do ou aumentado d√≠vidas, enquanto para pessoas sem defici√™ncia, essa porcentagem foi de **{nao_pcd_sim_divida:.1f}%**. Isso sugere uma potencial vulnerabilidade maior para pessoas com defici√™ncia em rela√ß√£o ao endividamento.")

                # --- IA: Resumo Autom√°tico
                st.markdown("---")
                st.subheader("ü§ñ An√°lise Autom√°tica da IA (experimental)")
                mostrar_ia = st.toggle("Mostrar an√°lise autom√°tica da IA para vulnerabilidade", value=False, key="toggle_ia_vuln")
                if mostrar_ia:
                    st.markdown("A IA pode gerar um resumo autom√°tico ou responder perguntas sobre a an√°lise de vulnerabilidade.")
                    if "historico_ia_vuln" not in st.session_state:
                        st.session_state.historico_ia_vuln = []
                    if st.button("Gerar Resumo Autom√°tico da IA", key="botao_resumo_ia_vuln"):
                        with st.spinner("A IA est√° analisando os dados..."):
                            resumo = f"""
**Resumo IA - Vulnerabilidade:**
- **Grupo analisado:** {vulnerability_vars.get(selected_v_var, selected_v_var)}
- **Vari√°vel de impacto:** {impact_vars.get(selected_impact_var, selected_impact_var)}
- **Principais distribui√ß√µes:** {crosstab_v.to_dict()}
"""
                            st.session_state.historico_ia_vuln.append({"pergunta": "Resumo Autom√°tico", "resposta": resumo})
                            st.markdown(resumo)
                    pergunta_livre = st.text_input("Pergunte algo √† IA sobre vulnerabilidade:", key="pergunta_livre_vuln")
                    if st.button("Perguntar √† IA", key="perguntar_ia_vuln"):
                        try:
                            import openai
                            client = openai.OpenAI(api_key=st.secrets.get("OPENAI_API_KEY", ""))
                            sample = df_vulnerability_analysis.sample(min(40, len(df_vulnerability_analysis))).to_dict(orient="records")
                            user_question = f"Considere esta amostra da an√°lise de vulnerabilidade: {sample}\nPergunta: {pergunta_livre}"
                            completion = client.chat.completions.create(
                                model="gpt-3.5-turbo", messages=[{"role": "user", "content": user_question}], temperature=0
                            )
                            ia_resp = completion.choices[0].message.content
                        except Exception as e:
                            ia_resp = f"N√£o foi poss√≠vel usar IA externa (API): {e}"
                        st.session_state.historico_ia_vuln.append({"pergunta": pergunta_livre, "resposta": ia_resp})
                        st.markdown("**Resposta da IA:**")
                        st.write(ia_resp)
                    if st.session_state.historico_ia_vuln:
                        with st.expander("Ver hist√≥rico de perguntas √† IA (vulnerabilidade)"):
                            for h in st.session_state.historico_ia_vuln[::-1]:
                                st.markdown(f"**Pergunta:** {h['pergunta']}")
                                st.markdown(h["resposta"])
                                st.markdown("---")
            else:
                st.warning("N√£o h√° dados v√°lidos para esta combina√ß√£o de vari√°veis com os filtros atuais.")
        else:
            st.info("Por favor, selecione as vari√°veis para a an√°lise de vulnerabilidade.")

    st.markdown("---")
