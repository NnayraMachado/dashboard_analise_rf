import streamlit as st
import pandas as pd
import plotly.express as px
import google.generativeai as genai
import re

# Checa se o DataFrame principal foi carregado
from utils.session import ensure_session_data
ensure_session_data()
    
df = st.session_state['df']
st.header("üí¨ Pergunte √† IA (Gemini)")

st.markdown("---")

# Configure API Gemini
genai.configure(api_key=st.secrets["GEMINI_API_KEY"])

# --- MAPA DE SIN√îNIMOS/COLUNAS PARA BUSCA AUTOM√ÅTICA ---
mapa_colunas = {
    "ID7": ["ra√ßa", "cor", "negro", "pardo", "branco", "ind√≠gena"],
    "ADAI_ID8": ["g√™nero", "sexo", "homem", "mulher", "masculino", "feminino"],
    "ADAI_CT4": ["territ√≥rio", "localidade", "munic√≠pio", "colatina", "baixo guandu"],
    "ID10": ["defici√™ncia", "pcd"],
    "PCT0": ["povo tradicional", "comunidade tradicional", "quilombola", "povo", "ind√≠gena"],
    "Idade": ["idade", "faixa et√°ria", "jovem", "idoso", "crian√ßa"],
    "ID11": ["escolaridade", "forma√ß√£o"],
    "ADAI_ID12": ["profiss√£o", "trabalho", "ocupa√ß√£o"],
    "ID12": ["religi√£o", "pr√°tica religiosa"],
    # Acrescente outros campos do seu interesse
}

# Fun√ß√µes auxiliares do seu painel:
def extrair_filtros(pergunta, mapa):
    """Procura sin√¥nimos na pergunta e mapeia para colunas"""
    filtros = {}
    for campo, palavras in mapa.items():
        for palavra in palavras:
            if re.search(rf'\b{palavra}\b', pergunta, re.IGNORECASE):
                filtros[campo] = palavra
                break
    return filtros

def aplicar_filtros(df, filtros):
    """Aplica os filtros no DataFrame"""
    df_filtrado = df.copy()
    for coluna, valor in filtros.items():
        # Tratamento especial para colunas num√©ricas
        if pd.api.types.is_numeric_dtype(df_filtrado[coluna]):
            m = re.search(r'(maior|acima|mais de) (\d+)', valor)
            if m:
                df_filtrado = df_filtrado[df_filtrado[coluna] > int(m.group(2))]
            else:
                m = re.search(r'(menor|abaixo|menos de) (\d+)', valor)
                if m:
                    df_filtrado = df_filtrado[df_filtrado[coluna] < int(m.group(2))]
        else:
            df_filtrado = df_filtrado[df_filtrado[coluna].astype(str).str.contains(valor, case=False, na=False)]
    return df_filtrado

def explicar_para_ia(pergunta, resultado):
    """Chama a IA Gemini para explicar, usando apenas o resultado filtrado"""
    contexto_metodologico = """
NOTA METODOL√ìGICA:
Este dashboard utiliza dados prim√°rios e secund√°rios coletados pela ADAI nos territ√≥rios 9, 10, 13, 14, 15 e 16 do Esp√≠rito Santo, referentes ao impacto do rompimento da barragem de Fund√£o (Samarco, Vale, BHP Billiton). Foram entrevistadas 624 fam√≠lias (1.794 pessoas) em setembro/outubro de 2023, usando question√°rio estruturado, a partir de amostragem representativa e snowball. Os resultados devem ser interpretados no contexto da pesquisa social, considerando limita√ß√µes pr√≥prias do m√©todo e em fase cont√≠nua de atualiza√ß√£o e an√°lise.
"""
    # Limita a amostra para IA n√£o travar, mas ainda representativa
    if len(resultado) > 80:
        sample_df = resultado.sample(80, random_state=42)
    else:
        sample_df = resultado
    prompt = (
    f"{contexto_metodologico}\n\n"
    f"Pergunta do usu√°rio: \"{pergunta}\"\n"
    f"Resultado filtrado (colunas e at√© 80 linhas):\n{sample_df.to_string(index=False)}\n\n"
    f"Explique para um p√∫blico leigo o que esse resultado representa, **sempre considerando a nota metodol√≥gica acima**. Destaque padr√µes, diferen√ßas ou curiosidades, mas N√ÉO invente nenhum valor que n√£o esteja nos dados apresentados. N√ÉO fa√ßa generaliza√ß√µes fora do contexto do desastre da barragem de Fund√£o/ADAI."
    )
    model = genai.GenerativeModel('gemini-1.5-flash')
    resposta = model.generate_content(prompt)
    return resposta.text

# Inicializa o hist√≥rico de chat
if "chat_history_gemini" not in st.session_state:
    st.session_state.chat_history_gemini = []

MAX_INPUT_CHARS = 400  # limite de caracteres para o input do usu√°rio

# Renderiza o hist√≥rico (perguntas e respostas)
for item in st.session_state.chat_history_gemini:
    with st.chat_message("user"):
        st.markdown(item["pergunta"])
    with st.chat_message("assistant"):
        st.markdown(item["resposta"])
        if "tabela" in item and item["tabela"] is not None:
            st.dataframe(item["tabela"])
        if "grafico" in item and item["grafico"] is not None:
            st.plotly_chart(item["grafico"], use_container_width=True)

# Orienta√ß√µes para o usu√°rio (insira aqui)
st.subheader("üìù Orienta√ß√µes para Perguntar √† IA Gemini")

st.info("""
**Como fazer perguntas para a IA?**

- Escreva d√∫vidas ou pedidos de informa√ß√£o de forma clara e objetiva.
- Exemplos:
    - _"Quantas mulheres negras moram em Colatina?"_
    - _"Qual a distribui√ß√£o de idade entre os quilombolas?"_
    - _"Quantos respondentes se declararam ind√≠genas em Baixo Guandu?"_
    - _"Como est√° a escolaridade dos moradores do territ√≥rio 14?"_

**Dicas importantes:**
- Utilize palavras-chave como: g√™nero, idade, ra√ßa/cor, munic√≠pio, escolaridade, trabalho, religi√£o, etc.
- Seja espec√≠fico sobre quem ou o qu√™ voc√™ quer saber (ex: ‚Äúem Baixo Guandu‚Äù, ‚Äúentre os jovens‚Äù, ‚Äúfam√≠lias chefiadas por mulheres‚Äù).
- Combine crit√©rios, se desejar, mas evite perguntas muito amplas ou vagas.
- Limite-se a perguntas simples, de prefer√™ncia com at√© dois filtros por vez, para melhores resultados.
- Caso a resposta pare√ßa estranha, incompleta ou confusa, tente reformular sua pergunta de forma mais direta.

---

:warning: **Aten√ß√£o!**
Esta fun√ß√£o de perguntas autom√°ticas para a IA **ainda est√° em desenvolvimento** e pode apresentar limita√ß√µes, respostas incompletas ou erros de interpreta√ß√£o.  
**Recomenda-se sempre revisar as respostas da IA** e, em caso de d√∫vida, consultar a equipe t√©cnica ou especialistas do projeto antes de tomar decis√µes com base nessas respostas.
""")

# Entrada do chat
user_input = st.chat_input("Digite sua pergunta para a IA...", max_chars=MAX_INPUT_CHARS, key="input_gemini")
if user_input:
    with st.spinner("Buscando resposta..."):
        filtros = extrair_filtros(user_input, mapa_colunas)
        if not filtros:
            resposta = "‚ùó N√£o consegui identificar filtros na pergunta. Tente usar termos como 'mulher', 'negro', 'Colatina', 'idade', etc."
            tabela = None
            grafico = None
        else:
            resultado = aplicar_filtros(df, filtros)
            resposta = f"Total de registros encontrados: **{len(resultado)}**"
            tabela = resultado if len(resultado) > 0 else None

            # Exemplo de gr√°fico autom√°tico (pode adaptar para outros tipos!)
            if len(filtros) == 1:  # s√≥ um filtro: exibe distribui√ß√£o por g√™nero, ra√ßa ou munic√≠pio se poss√≠vel
                coluna = list(filtros.keys())[0]
                if coluna in resultado.columns and resultado[coluna].nunique() < 10:
                    grafico = px.histogram(resultado, x=coluna, title=f"Distribui√ß√£o de {coluna}", text_auto=True)
                else:
                    grafico = None
            else:
                grafico = None

            # IA s√≥ chama se houver registros
            if len(resultado) > 0:
                with st.spinner("IA explicando o resultado..."):
                    explicacao = explicar_para_ia(user_input, resultado)
                    resposta += "\n\n#### üß† Explica√ß√£o da IA:\n" + explicacao
            else:
                resposta += "\n\nNenhum registro encontrado para os filtros aplicados."
        
        # Salva no hist√≥rico
        st.session_state.chat_history_gemini.append({
            "pergunta": user_input,
            "resposta": resposta,
            "tabela": tabela,
            "grafico": grafico
        })
        st.rerun()
